
# Reference documentation


## avx/vss/geometry.proto

This file describes the geometric messages used in other messages
from the API.

### EulerAngles

\brief Euler angles.

\note In AVX convention, yaw is the rotation around the Y axis, pitch is the
rotation around the X axis and roll is the rotation around the Z axis.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| yaw | [double](#double) |  | The rotation around the Y axis. |
| pitch | [double](#double) |  | The rotation around the X axis. |
| roll | [double](#double) |  | The rotation around the Z axis. |

### Vector3D

\brief Vector in a 3D referential.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| x | [double](#double) |  | Value on the X axis. |
| y | [double](#double) |  | Value on the Y axis. |
| z | [double](#double) |  | Value on the Z axis. |




## avx/vss/object_identifier.proto



### ObjectIdentifier

\brief Represents the unique identifier for a simulation object.

It applies on vehicles, pedestrians, static objects (e.g. road signs) or 
lighting systems.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| id | [string](#string) |  | Represents a unique identifier for the associated object. <br><br>\note The identifier is case sensitive. |




## avx/vss/resource_identifier.proto



### ResourceIdentifier

\brief This message is used to define a unique identifier for any element 
in the simulation.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| id | [string](#string) |  | The unique string that identifies the element. Most of the time,<br>the expected value is the full file name and path of the resource. |




## avx/vss/sensor_data_format.proto




### CameraDataFormat

\brief Types and formats of data produced by a camera.

The data types correspond to the image types (irradiance map, temperature
map, etc.) and are only used to describe images stored in shared memory.

Data formats correspond to the file format of the images (bmp, gif, etc.)
and are only used to write images to disk. These data formats are
therefore not available for storing data in shared memory.

| Name | Number | Description |
| ---- | ------ | ----------- |
| UNDEFINED_CAMERA_FORMAT | 0 | Undefined value (default value will apply). |
| RAW | 1 | RAW image format (default).<br><br>\note Can be used for dumping images or describing images stored in shared<br>memory. |
| BMP | 2 | BMP image format. |
| GIF | 3 | GIF image format. |
| JPEG | 4 | JPEG image format. |
| PNG | 5 | PNG image format. |
| TEMPERATURE_MAP | 6 | Temperature map (data type for thermal output). |
| SPECTRAL_IRRADIANCE_MAP | 7 | Spectral irradiance map (data type for camera lens output). |
| CUSTOM_DATA | 8 | Custom data (data type for custom GPU post-processing). |

### CameraGroundTruthDataFormat

\brief Types of recording formats available for GroundTruth data.

| Name | Number | Description |
| ---- | ------ | ----------- |
| UNDEFINED_GROUND_TRUTH_FORMAT | 0 | Undefined value. |
| DEPTH_MAP | 1 | Depth map format.<br>Represented by a byte array of 32 bits per pixel (RGBA image). |
| OPTICAL_FLOW | 2 | Optical flow format.<br>Represented by a byte array of 2 x 32 bits per pixel (horizontal speed <br>first, then vertical speed). |
| PIXEL_SEGMENTATION | 3 | Pixel Segmentation format.<br>Represented by a byte array of 24 bits per pixel (RGB image). |

### LidarDataFormat

\brief Types of lidar data formats.

| Name | Number | Description |
| ---- | ------ | ----------- |
| UNDEFINED_LIDAR_FORMAT | 0 | Undefined value (default value will apply). |
| POINT_CLOUD | 1 | Point cloud data format (default value). |
| WAVEFORM | 2 | Waveform data format. |
| CONTRIBUTIONS | 3 | Contributions data format. |
| LENS_OUTPUT | 4 | Lens output data format. |

### OutputFormat

\brief Types of recording formats available for radar and lidar sensors.

| Name | Number | Description |
| ---- | ------ | ----------- |
| UNDEFINED | 0 | Undefined value (default will apply). |
| TEXT | 1 | Text format (default). |
| PROTOBUF | 2 | Protobuf format. |

### PixelFormat

\brief Pixel format of data generated by a camera.

This format describes the type of data stored (byte or float) as well as 
how the data is arranged.

\note In addition to the usages mentioned below, 
each pixel format is possible for the output of a camera with 
custom post-processing, based on the Custom Output Format 
defined in the camera model.

| Name | Number | Description |
| ---- | ------ | ----------- |
| UNDEFINED_PIXEL_FORMAT | 0 | Undefined value (default value will apply). |
| RGBA32 | 1 | Rgba32 represents the sRGB format with an alpha channel and 32 bits per <br>pixel. Each channel (red, green, blue, and alpha) is assigned 8 bits per<br>pixel. (This is the default value.)<br><br>Format used for Camera Output (Image) and Imager Output (Injection) <br>when alpha channel is enabled in the simulation parameters. |
| RGB24 | 3 | Rgb24 represents the sRGB format with 24 bits per pixel. Each channel <br>(red, green, blue) is assigned 8 bits per pixel.<br><br>Format used for Camera Output (Image) and Imager Output (Injection)<br>when alpha channel is disabled in the simulation parameters, as well as <br>for ground truth pixel segmentation output. |
| GRAY8 | 2 | Gray8 pixel format which displays one grayscale channel with 8 bits per<br>pixel, allowing 256 shades of gray.<br><br>Format used for thermal camera image output. |
| FLOAT32 | 4 | The Float32 pixel format represents a float channel with 32 bits per<br>pixel. <br><br>Format used for thermal camera temperature map output and ground<br>truth depth map output. |
| FLOAT64 | 5 | The Float64 pixel format represents 2 channels of floating point numbers<br>with 32 bits per pixel. Each channel is assigned 32 bits per pixel.<br><br>Format used for ground truth optical flow output. |
| FLOAT128 | 6 | The Float128 pixel format represents 4 channels of floating point numbers<br>with 32 bits per pixel. Each channel is assigned 32 bits per pixel.<br><br>Format used for Lens Output (Light). |

### RadarDataFormat

\brief Types of radar data formats.

| Name | Number | Description |
| ---- | ------ | ----------- |
| UNDEFINED_RADAR_FORMAT | 0 | Undefined value (default will apply). |
| RADAR_OUTPUT | 1 | Full radar output (default). |
| RANGE_DOPPLER | 2 | Range doppler data format. |
| FREQUENCY_PULSE | 3 | Frequency pulse data format. |
| DIGITAL_SAMPLES | 4 | Digital sample data format. |



## avx/vss/status.proto



### Status

\brief The status message returned by AVX for any procedure call.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| code | [StatusCode](#statuscode) |  | The status of the procedure call. |
| message | [string](#string) |  | An error message as text string. |


### StatusCode

\brief List of status code values.

| Name | Number | Description |
| ---- | ------ | ----------- |
| SUCCESS | 0 | Returned when successful. |
| UNKNOWN_FAILURE | 1 | Returned whenever there is an ERROR on AVX side. |



## avx/vss/tag_colors.proto



### Color

\brief Defines a color in RGB format


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| red | [uint32](#uint32) |  | The red component, between 0 and 255. |
| green | [uint32](#uint32) |  | The green component, between 0 and 255. |
| blue | [uint32](#uint32) |  | The blue component, between 0 and 255. |

### PixelSegmentationMapping

\brief Defines a mapping table of tags and colors.

\note Tags can be predefined AVxcelerate tags or user custom tags. 
\note Tags are case sensitive.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| tag_color_map | [PixelSegmentationMapping.TagColorMapEntry](#tagcolormapentry) | repeated | The tag-color mapping table. |

### PixelSegmentationMapping-TagColorMapEntry




| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| key | [string](#string) |  |  |
| value | [Color](#color) |  |  |




## avx/vss/data_access/sensor_data_access.proto





### DataAccess

\brief AVX Sensor Data Access Service

This service allows an external software to request sensor
data during the simulation.

| Method Name | Request Type | Response Type | Description |
| ----------- | ------------ | ------------- | ------------|
| RequestData | [SensorDataIdentifier](#sensordataidentifier) | [SensorDataBuffer](#sensordatabuffer) | Requests the produced sensor data using the specified sensor data <br>identifier.<br><br>Returns the requested data as a serialized sensor data buffer.<br><br>\note This service has a message size limitation of 2 gigabytes. |
| RequestDataStream | [SensorDataIdentifier](#sensordataidentifier) | [SensorDataBuffer](#sensordatabuffer) stream | Requests the produced sensor data using the specified sensor data <br>identifier.<br><br>Returns the requested data as a stream of sensor data buffer.<br><br>\note This service has no message size limitation. |


## avx/vss/data_access/sensor_data_buffer.proto



### SensorDataBuffer

\brief Sensor data returned by the RequestData procedure
serialized as byte array.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| data | [bytes](#bytes) |  | A sensor data buffer serialized using vss.sensor_data.SensorData proto <br>message. |




## avx/vss/data_access/sensor_data_description.proto



### CameraFeedback

\brief Camera sensor parameters that were used to produce this image.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| exposure_time | [google.protobuf.Duration](#duration) |  | Value of the exposure time.<br>The value is represented as a count of seconds and fractions of seconds <br>at nanosecond resolution. |
| gain | [double](#double) |  | Value of the gain. |
| injection_time | [google.protobuf.Int32Value](#int32value) |  | Value of the injection time.<br><br>\note This data only makes sense when the injection mode is activated<br>as it is retrieved and encoded in the pixel defined in the injection<br>parameters. |

### CameraMetadata

\brief Metadata associated to a data produced by a camera sensor.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| formats | [vss.CameraDataFormat](#cameradataformat) | repeated | Available camera output types.<br>Can be one of the following: RAW, TEMPERATURE_MAP, SPECTRAL_IRRADIANCE_MAP<br>or CUSTOM_DATA. |
| image_width | [int32](#int32) |  | The width of the camera output. |
| image_height | [int32](#int32) |  | The height of the camera output. |
| pixel_format | [vss.PixelFormat](#pixelformat) |  | The pixel format of the image. |
| ground_truth_formats | [vss.CameraGroundTruthDataFormat](#cameragroundtruthdataformat) | repeated | The list of ground truth data available. |
| nb_of_2Dbounding_boxes | [google.protobuf.Int32Value](#int32value) |  | The number of 2D bounding boxes that have been produced. |

### LidarMetadata

\brief Metadata associated to a data produced by a lidar sensor.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| formats | [vss.LidarDataFormat](#lidardataformat) | repeated | Formats available for a lidar output. |
| resolution | [Resolution](#resolution) |  | \c Resolution. |

### RadarDebugViewMetadata

\brief The data description of the radar's debug view output.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| image_width | [int32](#int32) |  | The width of the debug view's image output. |
| image_height | [int32](#int32) |  | The height of the debug view's image output. |
| pixel_format | [vss.PixelFormat](#pixelformat) |  | The pixel format of the image. |
| mode_identifier | [google.protobuf.Int32Value](#int32value) |  | The identifier of the corresponding radar mode. |

### RadarMetadata

\brief Metadata associated to a data produced by a radar sensor.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| formats | [vss.RadarDataFormat](#radardataformat) | repeated | Formats available for a radar output. |
| mode_identifier | [google.protobuf.Int32Value](#int32value) |  | The mode identifier. |
| tx_identifier | [google.protobuf.Int32Value](#int32value) |  | The transmitter antenna identifier. |
| tx_waveform_reported | [bool](#bool) |  | Indicates whether one or more TX waveform data are available. |

### Resolution

\brief Resolution of a lidar output.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| horizontal_resolution | [int32](#int32) |  | Horizontal resolution of lidar. |
| vertical_resolution | [int32](#int32) |  | Vertical resolution of lidar. |

### SensorDataDescription

\brief Content of the notifications sent any time sensor data is produced.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| sensor_id | [vss.ResourceIdentifier](#resourceidentifier) |  | The identifier of the sensor which produced the data.<br><br>\note The identifier corresponds to the identifier defined in<br>the sensor configuration. |
| data_id | [SensorDataIdentifier](#sensordataidentifier) |  | **Deprecated.** The identifier of the produced data.<br>To be used by the subscriber to retrieve the sensor data.<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using data_by_identifiers instead <br>(see SensorDataInfo.data_id). |
| simulation_time | [google.protobuf.Duration](#duration) |  | The simulation time of the produced data. |
| metadata | [SensorMetadata](#sensormetadata) |  | **Deprecated.** \c SensorMetadata.<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using data_by_identifiers instead<br>(see SensorDataInfo.metadata). |
| data_by_identifiers | [SensorDataInfo](#sensordatainfo) | repeated | \c SensorDataInfo.<br>Provides metadata description for the data produced by one sensor<br>in a single frame. |

### SensorDataInfo

\brief Sensor data info that contains sensor metadata for a given data 
 identifier.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| data_id | [SensorDataIdentifier](#sensordataidentifier) |  | The identifier of the produced data.<br>To be used by the subscriber to retrieve the sensor output data. |
| metadata | [SensorMetadata](#sensormetadata) |  | \c SensorMetadata. |

### SensorMetadata




| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| camera_metadata | [CameraMetadata](#camerametadata) |  | \c CameraMetadata. |
| lidar_metadata | [LidarMetadata](#lidarmetadata) |  | \c LidarMetadata. |
| radar_metadata | [RadarMetadata](#radarmetadata) |  | \c RadarMetadata. |
| radar_debug_view_metadata | [RadarDebugViewMetadata](#radardebugviewmetadata) |  | \c RadarDebugViewMetadata. |
| camera_feedback | [CameraFeedback](#camerafeedback) |  | Current values of the camera sensor parameters exposed to the<br>feedback control that were used to produce this data. |
| data_serialized | [bool](#bool) |  | Indicates if the data were serialized during the simulation. |
| deploy_host_address | [string](#string) |  | Deploy host address where the sensor data was generated. |
| data_access_server_port | [google.protobuf.Int32Value](#int32value) |  | The TCP port used to communicate with the data access server.<br>If no value provided, data are available only on the shared memory |




## avx/vss/data_access/sensor_data_identifier.proto



### SensorDataIdentifier

\brief Key to retrieve a sensor data.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| data_id | [string](#string) |  | A unique identifier for a produced sensor data. |




## avx/vss/data_access/sensor_data_output_notification.proto





### SensorDataNotifier

\brief AVX Sensor Data Notifier Service

This service allows to get notified when new sensor data is available in 
the data store.

| Method Name | Request Type | Response Type | Description |
| ----------- | ------------ | ------------- | ------------|
| Subscribe | [.google.protobuf.Empty](#empty) | [SensorDataDescription](#sensordatadescription) stream | Subscribes to the stream publishing notifications about new sensor data<br>in the data store. This stream ends when the simulation is completed.<br><br>Returns a stream of sensor data descriptions containing all needed <br>information to identify the type of the newly generated data and to <br>request it from the data store. |


## avx/vss/feedback_control/brown_distortion.proto



### BrownDistortion

\brief Definition of the brown distortion.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| radial_distortion | [BrownRadialDistortion](#brownradialdistortion) |  | \c BrownRadialDistortion. |
| tangential_distortion | [BrownTangentialDistortion](#browntangentialdistortion) |  | \c BrownTangentialDistortion. |

### BrownRadialDistortion

\brief %Lens radial distortion coefficients for Brown-Conrady distortion 
model (k1, k2, k3).


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| k1 | [google.protobuf.DoubleValue](#doublevalue) |  | K1 coefficient value of radial distortion. |
| k2 | [google.protobuf.DoubleValue](#doublevalue) |  | K2 coefficient value of radial distortion. |
| k3 | [google.protobuf.DoubleValue](#doublevalue) |  | K3 coefficient value of radial distortion. |

### BrownTangentialDistortion

\brief %Lens tangential distortion coefficients for Brown-Conrady distortion
model (p1, p2).


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| p1 | [google.protobuf.DoubleValue](#doublevalue) |  | P1 coefficient value of tangential distortion. |
| p2 | [google.protobuf.DoubleValue](#doublevalue) |  | P2 coefficient value of tangential distortion. |




## avx/vss/feedback_control/feedback_control.proto





### FeedbackControl

\brief AVX Feedback Control Service

This service is used to update specific parameters of sensors 
during the simulation. It could be used to implement an auto adaptive 
algorithm.

| Method Name | Request Type | Response Type | Description |
| ----------- | ------------ | ------------- | ------------|
| Send | [FeedbackControlDescription](#feedbackcontroldescription) | [.vss.Status](#status) | Sends a sensor (camera, lidar, radar) feedback control.<br>Returns a processing Status.<br><br>Called by an external software when it needs to update sensor parameters. |


## avx/vss/feedback_control/feedback_control_camera_parameters.proto



### AdvancedChromaticAberration

\brief Advanced Chromatic Aberration Parameters


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| focal_lengths | [SpectralFocalLengthDistribution](#spectralfocallengthdistribution) |  | Focal length of the lens system. |

### CircularAperture

\brief Circular Aperture Shape


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| aperture_area | [google.protobuf.DoubleValue](#doublevalue) |  | The aperture area.<br><br>Unit: square meters (m^2) |

### CustomChromaticDispersion

\brief Custom Chromatic Dispersion Parameters


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| focal_shift | [double](#double) |  | Focal length difference between the maximum and minimum wavelengths. <br><br>Unit: meter (m) |

### Demosaicing

\brief Parameters for the Physics-based Camera Demosaicing Output


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| bit_depth_reduction | [google.protobuf.Int32Value](#int32value) |  | Number of bits for the data encoding. |

### Electronics

\brief Camera Electronics Parameters

\note Changing the result conversion type during the simulation 
is not allowed.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| bits | [google.protobuf.Int32Value](#int32value) |  | The number defining the native bit depth of the camera. |
| gain | [google.protobuf.DoubleValue](#doublevalue) |  | The voltage gain of the camera.<br><br>Unit: dB |
| demosaicing | [Demosaicing](#demosaicing) |  | \c Demosaicing output. |
| injection | [Injection](#injection) |  | \c Injection output. |

### FeedbackControlCameraParameters

\brief This message is used to update one or several parameters of a camera
sensor during the simulation.

Every time AVX is called with this message, it retrieves the last received
values and applies the updates to the camera model to compute
the next output.

\note At least one parameter must be provided at each call.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| lens | [Lens](#lens) |  | %Lens parameters. |
| imager | [Imager](#imager) |  | %Imager parameters. |
| electronics | [Electronics](#electronics) |  | Electronics (post-processing) parameters. |

### FisheyePolynomialDistortion

\brief Fisheye Distortion Parameters


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| a1 | [google.protobuf.DoubleValue](#doublevalue) |  | A1 coefficient value of fisheye parameter. |
| a2 | [google.protobuf.DoubleValue](#doublevalue) |  | A2 coefficient value of fisheye parameter. |
| a3 | [google.protobuf.DoubleValue](#doublevalue) |  | A3 coefficient value of fisheye parameter. |
| a4 | [google.protobuf.DoubleValue](#doublevalue) |  | A4 coefficient value of fisheye parameter. |
| a5 | [google.protobuf.DoubleValue](#doublevalue) |  | A5 coefficient value of fisheye parameter. |

### Imager

\brief Camera Imager System Parameters

Parameters of the camera imager: resolution, exposure time, 
read out noise and thermal noise model.

\note Changing the thermal noise model during the simulation is not allowed.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| resolution | [ImagerResolution](#imagerresolution) |  | \c ImagerResolution. |
| exposure_time | [google.protobuf.DoubleValue](#doublevalue) |  | Exposure time value.<br><br>Unit: seconds (s) |
| readout_noise | [ReadoutNoise](#readoutnoise) |  | \c ReadoutNoise. |
| thermal_noise_simple | [ThermalNoiseSimpleModel](#thermalnoisesimplemodel) |  | \c ThermalNoiseSimpleModel. |
| thermal_noise_advanced | [ThermalNoiseAdvancedModel](#thermalnoiseadvancedmodel) |  | \c ThermalNoiseAdvancedModel. |

### ImagerResolution

\brief Resolution of the Imager

\note Changing the sensor resolution does not update the resolution
of the rendering window.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| width | [google.protobuf.Int32Value](#int32value) |  | Width of the sensor in number of pixels. |
| height | [google.protobuf.Int32Value](#int32value) |  | Height of the sensor in number of pixels. |

### Injection

\brief Parameters for the Injection Data Output


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| time_encoding | [InjectionTimeEncoding](#injectiontimeencoding) |  | \c InjectionTimeEncoding. |

### InjectionTimeEncoding

\brief The Timestamp Encoding


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| row | [google.protobuf.Int32Value](#int32value) |  | Row position of the pixel in which the simulation time is encoded. |
| column | [google.protobuf.Int32Value](#int32value) |  | Column position of the pixel in which the simulation time is encoded. |

### Lens

\brief Camera %Lens System Parameters

Parameters of the camera lens system: focal length, distortion model, 
shape of the lens' aperture, and type of chromatic aberration.

\note Changing the lens distortion model or the aperture shape 
during the simulation is not allowed.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| fisheye_polynomial_distortion | [FisheyePolynomialDistortion](#fisheyepolynomialdistortion) |  | Polynomial distortion parameters (for fisheye cameras). |
| brown_distortion | [BrownDistortion](#browndistortion) |  | Brown distortion parameters (for cameras with standard field of view). |
| focal_length | [google.protobuf.DoubleValue](#doublevalue) |  | **Deprecated.** Focal length of the lens.<br><br>Unit: meters (m)<br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using one of the two possibilities of <br>lens_chromatic_aberration instead: SimpleChromaticAberration or <br>AdvancedChromaticAberration. |
| circular | [CircularAperture](#circularaperture) |  | Circular aperture. |
| regular_convex | [RegularConvexPolygonAperture](#regularconvexpolygonaperture) |  | Regular convex polygon aperture. |
| simple_chromatic_aberration | [SimpleChromaticAberration](#simplechromaticaberration) |  | \c Simple chromatic aberration. |
| advanced_chromatic_aberration | [AdvancedChromaticAberration](#advancedchromaticaberration) |  | \c Advanced chromatic aberration. |

### ReadoutNoise

\brief Readout Noise Parameters


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| readout_noise_average | [google.protobuf.DoubleValue](#doublevalue) |  | Average value of the Gaussian distribution.<br><br>Unit: number of electrons. |
| readout_noise_standard | [google.protobuf.DoubleValue](#doublevalue) |  | Standard deviation of the Gaussian distribution.<br><br>Unit: number of electrons. |

### RegularConvexPolygonAperture

\brief Polygonal Aperture Shape


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| aperture_area | [google.protobuf.DoubleValue](#doublevalue) |  | The aperture area.<br><br>Unit: square meters (m^2) |
| offset_angle | [google.protobuf.DoubleValue](#doublevalue) |  | The offset angle.<br><br>Unit: radians (rad) |
| edge_number | [google.protobuf.Int32Value](#int32value) |  | The number of aperture sides/edges. |

### SimpleChromaticAberration

\brief Simple Chromatic Aberration Parameters

\note It is not possible to change from a Chromatic Dispersion Preset
to a Custom Chromatic Dispersion or vice-versa.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| focal_length | [google.protobuf.DoubleValue](#doublevalue) |  | Focal length of the lens system.<br><br>Unit: meter (m) |
| wavelength_of_focal_length | [google.protobuf.DoubleValue](#doublevalue) |  | Wavelength at which the focal length is not affected<br>by chromatic aberration.<br>Unit: meter (m) |
| preset_chromatic_dispersion | [PresetChromaticDispersion](#presetchromaticdispersion) |  | Preset chromatic dispersion |
| custom_chromatic_dispersion | [CustomChromaticDispersion](#customchromaticdispersion) |  | Custom chromatic dispersion |

### SpectralFocalLengthDistribution

\brief Spectral Focal Length Distribution


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| focal_length_390 | [double](#double) |  | Distance between the optical center of the lens and the focal point for <br>the 390 wavelength.<br><br>Unit: meter (m) |
| focal_length_427 | [double](#double) |  | Distance between the optical center of the lens and the focal point for <br>the 427 wavelength.<br><br>Unit: meter (m) |
| focal_length_464 | [double](#double) |  | Distance between the optical center of the lens and the focal point for <br>the 464 wavelength.<br><br>Unit: meter (m) |
| focal_length_502 | [double](#double) |  | Distance between the optical center of the lens and the focal point for <br>the 390 wavelength.<br>Unit: meter (m) |
| focal_length_539 | [double](#double) |  | Distance between the optical center of the lens and the focal point for <br>the 502 wavelength.<br><br>Unit: meter (m) |
| focal_length_577 | [double](#double) |  | Distance between the optical center of the lens and the focal point for <br>the 539 wavelength.<br><br>Unit: meter (m) |
| focal_length_614 | [double](#double) |  | Distance between the optical center of the lens and the focal point for <br>the 577 wavelength.<br><br>Unit: meter (m) |
| focal_length_652 | [double](#double) |  | 652 between the optical center of the lens and the focal point for <br>the 390 wavelength.<br><br>Unit: meter (m) |

### ThermalNoiseAdvancedModel

\brief Thermal Noise Parameters for the Advanced Model


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| dark_current_reference_value | [google.protobuf.DoubleValue](#doublevalue) |  | Dark current reference value.<br><br>Unit: number of electrons per second |
| dark_current_reference_temperature | [google.protobuf.DoubleValue](#doublevalue) |  | Dark current reference temperature.<br><br>Unit: Kelvin (K) |
| imager_temperature | [google.protobuf.DoubleValue](#doublevalue) |  | Imager temperature.<br><br>Unit: Kelvin (K) |
| dark_current_coefficient | [google.protobuf.DoubleValue](#doublevalue) |  | Dark current temperature coefficient.<br><br>Unit: Kelvin (K) |

### ThermalNoiseSimpleModel

\brief Thermal Noise Parameters for the Simple Model


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| dark_current_average_value | [google.protobuf.DoubleValue](#doublevalue) |  | Average dark current value.<br><br>Unit: number of electrons per second |


### PresetChromaticDispersion

\brief Chromatic Dispersion Presets

| Name | Number | Description |
| ---- | ------ | ----------- |
| NONE | 0 |  |
| LOW | 1 |  |
| MEDIUM | 2 |  |
| HIGH | 3 |  |



## avx/vss/feedback_control/feedback_control_description.proto



### FeedbackControlDescription

\brief This message is used to update one or several parameters of a
sensor during the simulation.

Contains the sensor parameters to be updated.

Every time AVX is called with this message, it retrieves the last received
values and applies the updates to the sensor model to compute
the next output.

\note At least one parameter must be provided at each call.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| sensor_id | [string](#string) |  | The identifier of the sensor as defined in the sensor configuration.<br><br>\note This identifier is required for each call and must identify<br>a sensor. |
| feedback_control_camera_parameters | [FeedbackControlCameraParameters](#feedbackcontrolcameraparameters) |  | This message is used to update a camera parameters during <br>the simulation. |
| feedback_control_radar_parameters | [FeedbackControlRadarParameters](#feedbackcontrolradarparameters) |  | This message is used to update a radar parameters during <br>the simulation. |
| feedback_control_lidar_parameters | [FeedbackControlLidarParameters](#feedbackcontrollidarparameters) |  | This message is used to update a lidar parameters during <br>the simulation. |
| enable_sensor_protection | [SensorProtectionEnabler](#sensorprotectionenabler) |  | Enables IP protection for the sensor. When IP protection is enabled for a<br>radar, no waveform report is generated for this radar. This has no effect<br>on any other sensor.<br><br>\note IP protection is delivered as a beta feature in the current release. |

### SensorProtectionEnabler

\brief This message is used to enable sensor protection.

\note Once enabled, IP protection cannot be disabled.





## avx/vss/feedback_control/feedback_control_lidar_parameters.proto



### AnalogToDigitalConverter

\brief Definition of the analog-to-digital converter.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| sampling_frequency | [google.protobuf.DoubleValue](#doublevalue) |  | Sampling Frequency of the analog-to-digital converter defining the temporal<br>resolution, i.e. the spatial accuracy (a = c / f).<br><br>Unit: hertz (Hz) |
| bit_resolution | [google.protobuf.Int32Value](#int32value) |  | Number of bits used for the waveform amplitude in the analog-to-digital<br>converter. |

### BeamDivergence

\brief Divergence of the gaussian beam.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| horizontal | [google.protobuf.DoubleValue](#doublevalue) |  | Horizontal divergence of the gaussian beam.<br><br>Unit: radians (rad) |
| vertical | [google.protobuf.DoubleValue](#doublevalue) |  | Vertical divergence of the gaussian beam.<br><br>Unit: radians (rad) |

### BeamShapeIntensityFile

\brief Intensity of the beam.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| intensity_file | [bytes](#bytes) |  | Byte array representing the beam spatial shape's <br>pattern table. |
| file_type | [IntensityFileType](#intensityfiletype) |  | Type of the intensity file.<br><br>\note If no file type is provided, the default value will be considered<br>as the type of the intensity file. |

### FeedbackControlLidarParameters

\brief This message is used to update one or several parameters of a lidar
sensor during the simulation.

Indicates on which type of lidar values are applied.

Every time AVX is called with this message, it retrieves the last received
values and applies the updates to the lidar model to compute the next output.

\note At least one parameter must be provided at each call.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| rotating_lidar | [RotatingLidar](#rotatinglidar) |  | \c RotatingLidar. |
| flash_lidar | [FlashLidar](#flashlidar) |  | \c FlashLidar. |

### FieldOfView

\brief Field of view definition.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| horizontal | [google.protobuf.DoubleValue](#doublevalue) |  | Horizontal field of view of the receiver.<br><br>Unit: radians (rad) |
| vertical | [google.protobuf.DoubleValue](#doublevalue) |  | Vertical field of view of the receiver.<br><br>Unit: radians (rad) |

### Firing

\brief Parameters of a lidar firing sequence.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| time | [google.protobuf.DoubleValue](#doublevalue) |  | Time offset of the firing.<br><br>Unit: seconds (s) |
| azimuth | [google.protobuf.DoubleValue](#doublevalue) |  | Rotation offset of the firing.<br><br>Unit: radians (rad) |
| elevation | [google.protobuf.DoubleValue](#doublevalue) |  | Elevation offset of the firing.<br><br>Unit: radians (rad) |
| peak_power | [google.protobuf.DoubleValue](#doublevalue) |  | Peak power of the firing.<br><br>\note The peak power (in Watts) is calculated based on the firing energy<br>(in Joules), the pulse shape and the pulse duration (in seconds).<br>This calculation should be considered when applying an update<br>that modifies the firings through the Feedback Control message.<br>For more information about how to calculate the peak power from the <br>pulse energy, refer to AVxcelerate Sensors Simulator User's Guide.<br><br>Unit: watts (W) |

### FiringSequence

\brief Description of the firing sequence.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| firings | [Firing](#firing) | repeated | Describes the firing sequence.<br><br>\note When adjusting the firing sequence via the feedback control, make<br>sure to update every parameter of the sequence to keep it consistent.<br>Sending a partial update (updating only one of the parameters) will<br>cause other parameters to use default values. |

### FlashLidar

\brief Parameters for a flashing lidar.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| emitter | [FlashLidarEmitter](#flashlidaremitter) |  | \c FlashLidarEmitter. |
| receiver | [FlashLidarReceiver](#flashlidarreceiver) |  | \c FlashLidarReceiver. |

### FlashLidarEmitter

\brief Emitter parameters of the flashing lidar.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| frequency | [google.protobuf.DoubleValue](#doublevalue) |  | Frequency of the laser fan shots.<br><br>Unit: hertz (Hz) |
| laser_pulse | [Pulse](#pulse) |  | \c Pulse |
| gaussian_beam_shape | [GaussianBeamShape](#gaussianbeamshape) |  | Parametric Gaussian beam shape. |
| beam_shape_intensity_file | [BeamShapeIntensityFile](#beamshapeintensityfile) |  | Intensity file describing the beam shape. |
| peak_power | [google.protobuf.DoubleValue](#doublevalue) |  | Maximum power emitted by the laser pulse.<br><br>Unit: watts (W) |

### FlashLidarReceiver

\brief Receiver parameters of the flashing lidar.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| lens_system | [LensSystem](#lenssystem) |  | \c LensSystem. |
| resolution_in_pixels | [Resolution](#resolution) |  | \c Resolution. |
| photo_detector | [PhotoDetector](#photodetector) |  | \c PhotoDetector. |
| processor | [LidarProcessor](#lidarprocessor) |  | \c LidarProcessor. |

### GaussianBeamShape

\brief Shape of the gaussian beam.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| divergence | [BeamDivergence](#beamdivergence) |  | \c BeamDivergence. |

### LensDistortion

\brief Lens distortion definition.

Definition of the lens distortion of the flashing Lidar receiver.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| brown_distortion | [BrownDistortion](#browndistortion) |  | Definition of the brown distortion. |

### LensSystem

\brief Lens system definition.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| aperture_area | [google.protobuf.DoubleValue](#doublevalue) |  | Aperture area of the receiver.<br><br>Unit: square meters (m^2) |
| field_of_view | [FieldOfView](#fieldofview) |  | \c FieldOfView. |
| lens_distortion | [LensDistortion](#lensdistortion) |  | \c LensDistortion. |

### LidarProcessor

\brief Lidar processor definition.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| analog_to_digital_converter | [AnalogToDigitalConverter](#analogtodigitalconverter) |  | \c AnalogToDigitalConverter. |
| max_returns | [google.protobuf.Int32Value](#int32value) |  | Maximum number of returns in the output. |
| max_range | [google.protobuf.DoubleValue](#doublevalue) |  | Maximum range of the lidar.<br><br>Unit: meters (m) |

### PhotoDetector

\brief Photo detector definition.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| responsivity | [google.protobuf.DoubleValue](#doublevalue) |  | Number of bits used for the waveform amplitude in the analog-to-digital<br>converter.<br><br>Unit: A/W<br><br>Range: [0,1] |
| max_current | [google.protobuf.DoubleValue](#doublevalue) |  | Saturation generated by the photo-detector.<br><br>Unit: amperes (A) |
| noise_standard_deviation | [google.protobuf.DoubleValue](#doublevalue) |  | Current standard deviation of noise.<br><br>Unit: amperes (A) |

### Pulse

\brief Pulse of the laser.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| wavelength | [google.protobuf.DoubleValue](#doublevalue) |  | Wavelength of the laser beam.<br><br>Unit: meters (m) |
| shape | [PulseShape](#pulseshape) |  | \c PulseShape. |
| duration | [google.protobuf.DoubleValue](#doublevalue) |  | Duration of the emitted laser pulse.<br><br>Unit: seconds (s) |
| extinction_coefficient | [google.protobuf.DoubleValue](#doublevalue) |  | Atmospheric attenuation coefficient.<br><br>Unit: m^-1 |

### Resolution

\brief Resolution of the detector, in pixels.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| horizontal | [google.protobuf.Int32Value](#int32value) |  | Number of horizontal pixels. |
| vertical | [google.protobuf.Int32Value](#int32value) |  | Number of vertical pixels. |

### RotatingLidar

\brief Parameters for a rotating lidar.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| rotation_speed | [google.protobuf.DoubleValue](#doublevalue) |  | Rotation speed of the rotating lidar.<br><br>Unit: number of rotations per second. |
| emitter | [RotatingLidarEmitter](#rotatinglidaremitter) |  | \c RotatingLidarEmitter. |
| receiver | [RotatingLidarReceiver](#rotatinglidarreceiver) |  | \c RotatingLidarReceiver. |

### RotatingLidarEmitter

\brief Emitter parameters of the rotating lidar.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| frequency | [google.protobuf.DoubleValue](#doublevalue) |  | Frequency of the laser fan shots.<br><br>Unit: hertz (Hz) |
| laser_pulse | [Pulse](#pulse) |  | \c Pulse. |
| beam_shape | [GaussianBeamShape](#gaussianbeamshape) |  | \c GaussianBeamShape. |
| firing_sequence | [FiringSequence](#firingsequence) |  | \c FiringSequence. |

### RotatingLidarReceiver

\brief Receiver parameters of the rotating lidar.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| aperture_area | [google.protobuf.DoubleValue](#doublevalue) |  | Aperture area of the receiver.<br><br>Unit: square meters (m^2) |
| photo_detector | [PhotoDetector](#photodetector) |  | \c PhotoDetector. |
| processor | [LidarProcessor](#lidarprocessor) |  | \c LidarProcessor. |


### IntensityFileType

Available types of intensity file.

| Name | Number | Description |
| ---- | ------ | ----------- |
| IES | 0 | Ies file (default type). |
| INTENSITY | 1 | Intensity file. |
| XMP | 2 | XMP file |

### PulseShape

\brief Shape of the emitted laser pulse.

| Name | Number | Description |
| ---- | ------ | ----------- |
| NONE_PULSE_SHAPE | 0 |  |
| GAUSSIAN | 1 |  |
| RECTANGULAR | 2 |  |
| TRIANGULAR | 3 |  |



## avx/vss/feedback_control/feedback_control_radar_parameters.proto



### ArbitraryChirp

\brief Arbitrary Chirp.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| center_frequency | [double](#double) |  | Center frequency of the analog-to-digital converter.<br><br>Unit: hertz (Hz). |
| sampling_rate | [double](#double) |  | Sampling frequency of the analog-to-digital converter.<br><br>Unit: hertz (Hz). |
| number_of_samples_per_chirp | [int32](#int32) |  | Number of samples per chirp. |
| chirp_interval | [double](#double) |  | Time interval between subsequent chirps.<br><br>Unit: seconds (s).<br><br>\note This parameter impacts the frame rate. |

### ArbitraryPulse

\brief Arbitrary pulse


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| center_frequency | [double](#double) |  | Center frequency of the analog-to-digital converter.<br><br>Unit: hertz (Hz) |
| bandwidth | [double](#double) |  | Bandwidth.<br><br>Unit: hertz (Hz) |
| number_of_frequency_samples_per_pulse | [int32](#int32) |  | Number of frequency samples per pulse. |
| pulse_interval | [double](#double) |  | Time interval between two subsequent pulses.<br><br>Unit: seconds (s)<br><br>\note This parameter impacts the frame rate. |

### ArbitrarySystemFrequencyModulatedContinuousWaveform

\brief Arbitrary system frequency modulated continuous waveform.

\note Arbitrary waveform is delivered as a beta feature 
in the current release.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| chirp_sequence | [ArbitraryChirp](#arbitrarychirp) | repeated | List of chirp definitions. |
| ramp_rate | [google.protobuf.DoubleValue](#doublevalue) |  | Ramp rate. |
| rx_components | [RxComponents](#rxcomponents) |  | \c RxComponents. |

### ArbitrarySystemPulseDopplerWaveform

\brief Arbitrary system pulse doppler waveform.

\note Arbitrary waveform is delivered as a beta feature 
in the current release.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| pulse_sequence | [ArbitraryPulse](#arbitrarypulse) | repeated | List of pulse definitions. |

### DeviceAntenna

\brief Parameters to be updated for a radar antenna.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| identifier | [google.protobuf.Int32Value](#int32value) |  | Identifier of the antenna.<br>To be considered as a key to modify an existing antenna.<br>\note It is not allowed to add or remove antennas. |
| position | [vss.Vector3D](#vector3d) |  | Position of the antenna relative to the radar device's position.<br><br>Unit: meters (m) |
| orientation | [vss.EulerAngles](#eulerangles) |  | Orientation of the antenna relative to the radar device's orientation.<br><br>Unit: radians (rad) |

### FeedbackControlRadarParameters

\brief This message is used to update one or several parameters of a radar
sensor during the simulation.

Every time AVX is called with this message, it retrieves the last received
values and applies the updates to the radar model to compute the next output.

\note At least one parameter must be provided at each call.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| tx_antennas | [DeviceAntenna](#deviceantenna) | repeated | List of Tx antennas to be updated. |
| rx_antennas | [DeviceAntenna](#deviceantenna) | repeated | List of Rx antennas to be updated. |
| modes | [Mode](#mode) | repeated | List of the modes to be updated. |

### FlatWindow

\brief Flat window model.


### FrequencyModulatedContinuousWaveform

\brief Frequency modulated continuous waveform.

Indicates which frequency modulated continuous waveform model is chosen.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| system_frequency_modulated_continuous_waveform | [SystemFrequencyModulatedContinuousWaveform](#systemfrequencymodulatedcontinuouswaveform) |  | \c SystemFrequencyModulatedContinuousWaveform. |
| performance_frequency_modulated_continuous_waveform | [PerformanceFrequencyModulatedContinuousWaveform](#performancefrequencymodulatedcontinuouswaveform) |  | \c PerformanceFrequencyModulatedContinuousWaveform. |
| arbitrary_system_frequency_modulated_continuous_waveform | [ArbitrarySystemFrequencyModulatedContinuousWaveform](#arbitrarysystemfrequencymodulatedcontinuouswaveform) |  | \c ArbitraryFrequencyModulatedContinuousWaveform. |

### HammingWindow

\brief Hamming window model.


### HannWindow

\brief Hann window model.


### Mode

\brief Parameters to be updated for a radar mode.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| identifier | [google.protobuf.Int32Value](#int32value) |  | Identifier of the mode.<br>To be considered as a key to modify an existing mode.<br>\note It is not allowed to add or remove modes. |
| waveform | [Waveform](#waveform) |  | \c Waveform. |
| range_doppler_processor | [RadarProcessor](#radarprocessor) |  | \c RadarProcessor. |
| start_delay | [google.protobuf.DoubleValue](#doublevalue) |  | Latency between the start of the frame and the first pulse or chirp sent<br>by the mode's CPI.<br>\note This parameter impacts the frame rate. |
| tx_antenna_ids | [int32](#int32) | repeated | List of the transmitting antenna IDs to use in this mode. |
| rx_antenna_ids | [int32](#int32) | repeated | List of the receiving antenna IDs to use in this mode. |
| activate_mode | [google.protobuf.BoolValue](#boolvalue) |  | Activation or deactivation of the mode. |
| Gain | [google.protobuf.DoubleValue](#doublevalue) |  | Gain. <br>Negative values correspond to a loss and positive values <br>correspond to an amplification, 0 being neutral.<br><br>Unit: dB<br><br>\note If no value is set, previous gain type and value are kept. <br>If a value is set, the new value is applied in Manual type whatever <br>the previous type (Automatic or Manual). |
| Noise | [google.protobuf.DoubleValue](#doublevalue) |  | Noise standard deviation.<br><br>Unit: dBW<br><br>\note If a value is set, noise is activated and value is applied. |
| tx_weighting | [TxWeighting](#txweighting) |  | \c TxWeighting. |

### Performance

\brief Parameters of the performance pulse doppler waveform


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| range_resolution | [google.protobuf.DoubleValue](#doublevalue) |  | Target range resolution of the output frame. <br><br>Unit: meters (m) |
| velocity_resolution | [google.protobuf.DoubleValue](#doublevalue) |  | Target velocity resolution of the output frame.<br><br>Unit: meters per seconds (m/s)<br><br>\note This parameter impacts the frame rate. |
| range_ambiguity | [google.protobuf.DoubleValue](#doublevalue) |  | Maximum unambiguous range or range period.<br><br>Unit: meters (m) |
| velocity_ambiguity | [google.protobuf.DoubleValue](#doublevalue) |  | Maximum unambiguous velocity or velocity period.<br><br>Unit: meters per seconds (m/s)<br><br>\note This parameter impacts the frame rate. |

### PerformanceFrequencyModulatedContinuousWaveform

\brief Performance frequency modulated continuous waveform.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| sampling_rate | [google.protobuf.DoubleValue](#doublevalue) |  | Sampling frequency of the analog-to-digital converter.<br><br>Unit: hertz (Hz) |
| performance | [Performance](#performance) |  | \c Performance. |
| rx_components | [RxComponents](#rxcomponents) |  | \c RxComponents. |

### PerformancePulseDopplerWaveform

\brief Performance pulse doppler waveform.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| performance | [Performance](#performance) |  | \c Performance. |

### PulseDopplerWaveform

\brief Pulse doppler waveform.

Indicates which pulse doppler waveform model is chosen.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| system_pulse_doppler_waveform | [SystemPulseDopplerWaveform](#systempulsedopplerwaveform) |  | \c SystemPulseDopplerWaveform. |
| performance_pulse_doppler_waveform | [PerformancePulseDopplerWaveform](#performancepulsedopplerwaveform) |  | \c PerformancePulseDopplerWaveform. |
| arbitrary_system_pulse_doppler_waveform | [ArbitrarySystemPulseDopplerWaveform](#arbitrarysystempulsedopplerwaveform) |  | \c ArbitrarySystemPulseDopplerWaveform |

### RadarProcessor

\brief Radar processor parameters.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| range_pixels | [google.protobuf.Int32Value](#int32value) |  | Range resolution of the output range doppler map image. |
| velocity_pixels | [google.protobuf.Int32Value](#int32value) |  | Velocity resolution of the output range doppler map image. |
| range_window | [Window](#window) |  | Range window of the output range doppler map image. |
| velocity_window | [Window](#window) |  | Velocity window of the output range doppler map image. |
| center_velocity | [google.protobuf.DoubleValue](#doublevalue) |  | Center value of the velocity range. |

### SystemFrequencyModulatedContinuousWaveform

\brief System frequency modulated continuous waveform.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| bandwidth | [google.protobuf.DoubleValue](#doublevalue) |  | Frequency bandwidth of the waveform.<br><br>Unit: hertz (Hz) |
| sampling_rate | [google.protobuf.DoubleValue](#doublevalue) |  | Sampling frequency of the analog-to-digital converter.<br><br>Unit: hertz (Hz) |
| number_of_samples_per_chirp | [google.protobuf.Int32Value](#int32value) |  | Number of samples per chirp. |
| chirp_interval | [google.protobuf.DoubleValue](#doublevalue) |  | Time interval between subsequent chirps, equal to the inverse of the<br>chirp repetition frequency.<br><br>Unit: seconds (s)<br><br>\note This parameter impacts the frame rate. |
| number_of_chirps_in_coherent_processing_interval | [google.protobuf.Int32Value](#int32value) |  | Number of chirps in one coherent processing interval (CPI).<br><br>\note This parameter impacts the frame rate. |
| rx_components | [RxComponents](#rxcomponents) |  | \c RxComponents. |

### SystemPulseDopplerWaveform

\brief System pulse doppler waveform.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| bandwidth | [google.protobuf.DoubleValue](#doublevalue) |  | Frequency bandwidth of the waveform.<br><br>Unit: hertz (Hz) |
| number_of_frequency_samples | [google.protobuf.Int32Value](#int32value) |  | Number of frequency samples. |
| pulse_interval | [google.protobuf.DoubleValue](#doublevalue) |  | Time interval between two subsequent pulses, equal to the inverse of the<br>pulse frequency.<br><br>Unit: seconds (s)<br><br>\note This parameter impacts the frame rate. |
| number_of_pulses_in_coherent_processing_interval | [google.protobuf.Int32Value](#int32value) |  | Number of pulses in one coherent processing interval (CPI).<br><br>\note This parameter impacts the frame rate. |

### TaylorWindow

\brief Taylor window model.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| side_lobe_level | [double](#double) |  | Ratio of the main peak value to the side-lobe peak. |

### TxWeighting

\brief Represents radar weighting sequences.
\note When adjusting the weighting sequence via the feedback control, be
sure to update each parameter of the sequence to keep it consistent.

\note Weighting sequence is delivered as a beta feature 
in the current release.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| weightings_by_transmitter | [WeightingByTransmitter](#weightingbytransmitter) |  | \c WeightingByTransmitter. |
| weightings_by_pulses_or_chirps | [WeightingByPulsesOrChirps](#weightingbypulsesorchirps) |  | \c WeightingByPulsesOrChirps. |

### Waveform

\brief Waveform model.

Indicates which waveform model is chosen.

\note Changing the waveform model during the simulation is not allowed.
If you do so, the message will be rejected.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| pulse_doppler_waveform | [PulseDopplerWaveform](#pulsedopplerwaveform) |  | \c PulseDopplerWaveform. |
| frequency_modulated_continuous_waveform | [FrequencyModulatedContinuousWaveform](#frequencymodulatedcontinuouswaveform) |  | \c FrequencyModulatedContinuousWaveform. |

### Weighting

\brief Represents a single weighting value with real and imaginary parts.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| real_part | [double](#double) |  | Real part of the complex weighting. |
| imaginary_part | [double](#double) |  | Imaginary part of the complex weighting. |

### WeightingByPulsesOrChirps

\brief Represents weightings described by pulses or chirps.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| weightings_by_transmitter | [WeightingByTransmitter](#weightingbytransmitter) | repeated | List of weightings by transmitter for each pulse or chirp. |

### WeightingByTransmitter

\brief Represents weightings described by the transmitter.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| weightings | [Weighting](#weighting) | repeated | List of weightings for each antenna or transmitter. |

### Window

\brief Window.

Indicates which window model is chosen.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| flat_window | [FlatWindow](#flatwindow) |  | \c FlatWindow. |
| hamming_window | [HammingWindow](#hammingwindow) |  | \c HammingWindow. |
| hann_window | [HannWindow](#hannwindow) |  | \c HannWindow. |
| taylor_window | [TaylorWindow](#taylorwindow) |  | \c TaylorWindow. |


### RxComponents

\brief Type of mixing for the comparison of emitted signal vs received 
signal.

| Name | Number | Description |
| ---- | ------ | ----------- |
| NONE_RXCOMPONENTS | 0 |  |
| IN_PHASE | 1 |  |
| IN_PHASE_AND_QUADRATURE | 2 |  |



## avx/vss/ground_truth_access/camera_ground_truth.proto



### PixelSegmentationTagColorMap

\brief The mapping table of tags and colors used in the simulation
for the pixel segmentation camera output.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| tag_color_map | [PixelSegmentationTagColorMap.TagColorMapEntry](#tagcolormapentry) | repeated | The tag-color mapping table. |
| status | [vss.Status](#status) |  | The status of the request |

### PixelSegmentationTagColorMap-TagColorMapEntry




| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| key | [string](#string) |  |  |
| value | [vss.Color](#color) |  |  |




## avx/vss/ground_truth_access/contribution_dictionary.proto



### AssetDescription

\brief This message describes the asset linked to the entity ID


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| instance_name | [string](#string) |  | The name of the simulation instance using the asset |
| asset_path | [string](#string) |  | The path to the asset loaded in the AVX simulation |

### ContributionDictionary

\brief This message contains a dictionary used to relate each entity ID 
in the contribution output to the description of the asset and its nodes.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| items | [EntityContributionDescription](#entitycontributiondescription) | repeated | The collection of items relating the entity ID <br>from the contribution output to the asset information. |
| status | [vss.Status](#status) |  | The status of the request |

### EntityContributionDescription

\brief This message describes the mesh node, its parent nodes 
and the asset linked to the entity ID.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| EntityID | [uint32](#uint32) |  | The ID of the entity in the simulation |
| asset_description | [AssetDescription](#assetdescription) |  | The description of the asset |
| node_hierarchy | [NodeDescription](#nodedescription) | repeated | The list of descriptions of the mesh node and all its parents |
| mesh_description | [MeshDescription](#meshdescription) |  | The description of the mesh |

### MeshDescription

\brief This message describes the mesh associated to the entity ID


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| mesh_part_name | [string](#string) |  | The name of the mesh part associated to the entity ID |
| material_path | [string](#string) |  | The path to the material part used by the mesh part |
| mesh_name | [string](#string) |  | The name of the mesh associated to the entity ID |

### NodeDescription

\brief This message describes a node linked to the entity ID


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| name | [string](#string) |  | The name of the node in the simulation |
| tags | [TagDescription](#tagdescription) | repeated | The tag(s) associated to the node |

### SensorIdentifier

\brief The identifier of the sensor as defined in the sensor configuration.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| sensor_id | [string](#string) |  | the sensor identity |

### TagDescription

\brief This message describes the tag associated to the entity ID


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| tag | [string](#string) |  | The name of the tag applied to the node in the asset |
| label | [string](#string) |  | The additional tag label applied to the node in the asset |




## avx/vss/ground_truth_access/ground_truth_data_helper.proto





### GroundTruthDataHelper

\brief AVX Ground Truth Helper Service

This service allows to acquire ground truth auxiliary information.

| Method Name | Request Type | Response Type | Description |
| ----------- | ------------ | ------------- | ------------|
| GetContributionDictionary | [SensorIdentifier](#sensoridentifier) | [ContributionDictionary](#contributiondictionary) | Requests a dictionary which offers the possibility to relate IDs <br>in the contribution output of the LiDAR specified in the request message <br>to the asset information. |
| GetPixelSegmentationTagColorMap | [.google.protobuf.Empty](#empty) | [PixelSegmentationTagColorMap](#pixelsegmentationtagcolormap) | Requests the mapping table of tags and colors used in the simulation<br>for the pixel segmentation camera output. |


## avx/vss/lighting_system_control/lighting_system.proto





### LightingSystem

\brief Lighting System service.

This service is used to manage lighting systems.

| Method Name | Request Type | Response Type | Description |
| ----------- | ------------ | ------------- | ------------|
| Switch | [.vss.ObjectIdentifier](#objectidentifier) | [.vss.Status](#status) | Changes the active lighting system. The input parameter identifies<br>the lighting system to activate. |


## avx/vss/lighting_system_control/lighting_system_control.proto





### LightingSystemControl

\brief Lighting System Control Service

This service is used to retrieve and update the flux, position and
orientation of each lamp contained in a lighting system.

| Method Name | Request Type | Response Type | Description |
| ----------- | ------------ | ------------- | ------------|
| Set | [LightingSystemState](#lightingsystemstate) | [.vss.Status](#status) | Updates the power of the lamps for a given set of projector/module/lamps.<br><br>Returns an error if any of the identities (lighting system/projector/module<br>/lamp) do not exist.<br><br>Does not change the value of a lamp if it is present in the loaded<br>projector but not in the ProjectorState message.<br>This procedure sends the new flux values to be applied. They will be<br>applied at the next call of the Simulation Service Update remote<br>procedure.<br>A successful vss.Status return means that the LightingSystemState message<br>is valid and will be applied. |
| Get | [LightingSystemName](#lightingsystemname) | [TimeStampedLightingSystemState](#timestampedlightingsystemstate) | Returns the LightingSystemState of the lighting system that has a<br>lighting_system_name matching the name given as argument. |


## avx/vss/lighting_system_control/lighting_system_state.proto



### LampState

\brief Message containing the state of a lamp.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| lamp_name | [string](#string) |  | Unique user-defined name of the lamp in the module. |
| flux | [double](#double) |  | Flux of the lamp.<br><br>Unit: lumens (lm) |

### LightingSystemName

\brief Message containing the lighting system name.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| name | [string](#string) |  | Unique user-defined name of the lighting system in the simulation. |

### LightingSystemState

\brief The message returned by AVX when the set procedure 
of the lighting system control service is called.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| lighting_system_name | [LightingSystemName](#lightingsystemname) |  | Lighting system name. |
| projectors_state | [ProjectorState](#projectorstate) | repeated | List of projectors contained in the lighting system. |

### ModuleState

\brief Message containing the state of a module.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| module_name | [string](#string) |  | Unique user-defined name of the module in the projector. |
| lamps_state | [LampState](#lampstate) | repeated | List of lamps contained in this module. |
| position | [vss.Vector3D](#vector3d) |  | Position of the module relative to the projector.<br><br>Unit: meters (m) |
| orientation | [vss.EulerAngles](#eulerangles) |  | Orientation of the module relative to the projector.<br><br>Unit: degrees |

### ProjectorState

\brief Message containing the state of a projector.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| projector_name | [string](#string) |  | Unique user-defined name of the projector in the lighting system. |
| modules_state | [ModuleState](#modulestate) | repeated | List of modules contained in this projector. |
| position | [vss.Vector3D](#vector3d) |  | Position of the projector relative to the lighting system origin.<br><br>Unit: meters (m) |
| orientation | [vss.EulerAngles](#eulerangles) |  | Orientation of the projector relative to the lighting system origin.<br><br>Unit: degrees |

### TimeStampedLightingSystemState

\brief The message returned by AVX when the get procedure
 of the lighting system control service is called.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| lighting_system_state | [LightingSystemState](#lightingsystemstate) |  | The state of the lighting system. |
| simulation_time | [google.protobuf.Duration](#duration) |  | The simulation time. |




## avx/vss/sensor_data/camera_output_data.proto



### BoundingBox2D

\brief Pixel coordinates representing a 2D bounding box.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| x_min | [int32](#int32) |  | x min pixel coordinates. |
| y_min | [int32](#int32) |  | y min pixel coordinates. |
| x_max | [int32](#int32) |  | x max pixel coordinates. |
| y_max | [int32](#int32) |  | y max pixel coordinates. |
| tag_name | [string](#string) |  | Tag associated to the object during the data preparation. |
| label | [string](#string) |  | Label associated to the object during the data preparation. |
| x_center | [int32](#int32) |  | x value of the center of the bounding box. |
| y_center | [int32](#int32) |  | y value of the center of the bounding box. |
| z_center | [float](#float) |  | Normalized depth of the center of the bounding box. |

### CameraGroundTruthData

\brief The Camera data for ground truth output.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| camera_format | [vss.CameraGroundTruthDataFormat](#cameragroundtruthdataformat) |  | Format of the ground truth data. |
| camera_data | [bytes](#bytes) |  | Byte array containing the ground truth data. |

### CameraImageData

\brief Camera data for image output.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| camera_format | [vss.CameraDataFormat](#cameradataformat) |  | Image type.<br>Can be one of the following: RAW, TEMPERATURE_MAP, SPECTRAL_IRRADIANCE_MAP<br>or CUSTOM_DATA. |
| camera_data | [bytes](#bytes) |  | Byte array containing the image.<br><br>\note For the special case of TEMPERATURE_MAP, camera_data contains the<br>temperature map as a string organized with one float value per pixel and<br>one line of text per line in the image. |

### CameraLensOutput

\brief The camera lens output is the spectral irradiance map 
produced by the lens of the camera sensor.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| resolution | [CameraResolution](#cameraresolution) |  | Resolution of the imager. |
| spectral_sampling | [SpectralSampling](#spectralsampling) |  | The spectral sampling. |
| camera_data | [float](#float) | repeated | Float array containing the spectral irradiance data.<br><br>The number of irradiance values is equal to the product of <br>the number of wavelengths times the number of pixels in the imager:<br>Nb_E = [nb_spectral_samples * nb_vertical_pixels * nb_horizontal_pixels]<br><br>The received data consists of 8 spectral values per pixel, <br>starting from the upper left corner of the image, line per line.<br><br>8 spectral values for pixel0 (vertical_coordinate0;horizontal_coordinate0)<br>8 spectral values for pixel1 (vertical_coordinate0;horizontal_coordinate1)<br>...<br><br><br>Unit: watts per square meter per nanometer (W/m^2/nm). |

### CameraResolution

\brief Resolution of the imager in number of pixels.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| width | [int32](#int32) |  | Width of the imager sensor in number of pixels. |
| height | [int32](#int32) |  | Height of the imager sensor in number of pixels. |

### SpectralSampling

\brief The spectral sampling.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| wavelength | [Wavelength](#wavelength) | repeated | The list of wavelengths constituting the spectral sampling.<br><br>The list must contain at least one wavelength. If it includes<br>several wavelengths, they must be provided in ascending order. |

### Wavelength

\brief The wavelength representation.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| value | [double](#double) |  | The value of the wavelength.<br><br>Unit: meters (m). |




## avx/vss/sensor_data/lidar_output_data.proto



### Contribution

\brief The lidar contribution.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| identity | [uint32](#uint32) |  | Identifier of a contributor (the material part the lidar encountered<br>during the simulation).<br><br>\note This identifier is automatically generated for<br>each material part during the data preparation. |
| weight | [float](#float) |  | The contribution ratio of the associated material part.<br>\note The ratio is expressed as a float value<br>comprised between [0 ; 1]. |

### ContributionData

\brief Lidar contribution output data.

The Contribution output file contains the ID of the contributors and
the ratio of their contribution for each point of the point cloud.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| contributions | [Contributions](#contributions) | repeated | An array of \c Contributions. |

### Contributions

\brief Group of \c Contribution.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| contributions | [Contribution](#contribution) | repeated | An array of lidar \c Contribution. |

### LensOutputData

\brief The lidar lens output data.

\note %Lens output data are stored sequentially.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| waveform_length | [int32](#int32) |  | The number of values for each sample. |
| data | [float](#float) | repeated | All the radiant flux values for all the samples. |

### LidarOutputData

\brief The lidar output data.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| point_clouds | [PointCloudData](#pointclouddata) |  | Lidar Output Point Cloud Data |
| waveforms | [WaveformData](#waveformdata) |  | ADC Output Digital Waveform Data |
| contributions | [ContributionData](#contributiondata) |  | Contribution List Data |
| lens_output | [LensOutputData](#lensoutputdata) |  | %Lens Output Radiant Flux Data |

### PointCloud

\brief The lidar point cloud output data.

Each point is defined by 4 float values defining:

  its position (x, y, z)

  its intensity


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| data | [float](#float) | repeated |  |

### PointCloudData

\brief The array of lidar point cloud data.

\note There is one point-cloud data for each lidar return.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| point_clouds | [PointCloud](#pointcloud) | repeated |  |

### WaveformData

\brief The lidar ADC Output Digital waveform data.

\note Digital waveforms are stored sequentially. Each single waveform
data has length.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| waveform_length | [int32](#int32) |  | The number of values contained in a single digital waveform. |
| data | [float](#float) | repeated | All the intensity values for all the waveforms. |




## avx/vss/sensor_data/radar_output_data.proto



### AnalogToDigitalConverterSamplesData

\brief The output radar data for analog-to-digital converter samples. 

Data are stored as multi-dimensional array of complex values or real
values, depending of the \c is_complex_valued flag of the message.
The physical dimensions are [TX, RX, chirp time, sample time] and
so the data contains:

    numTX x numRX x numChirpTime x numSampleTime complex numbers

 or equivalently

    2 x numTX x numRX x numChirpTime x numSampleTime real numbers

If the complex data is read sequentially, the outermost loop corresponds
to the TX dimension, then RX, then chirp time, and then sample
time which is the innermost.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| data | [float](#float) | repeated | The multi-dimensional array. |
| sample_time_domain | [Domain](#domain) |  | The number of time samples and the min/max values in the samples. |
| chirp_time_domain | [Domain](#domain) |  | The number of chirp time samples and the min/max values in the samples. |
| rx_identifiers | [int32](#int32) | repeated | Receiver antennas identifiers. |
| tx_identifiers | [int32](#int32) | repeated | Transmitter antennas identifiers. |
| is_complex_valued | [bool](#bool) |  | Indicates whether values are defined as complex numbers. |
| multiplexing | [Multiplexing](#multiplexing) |  | Multiplexing type. |

### ArbitraryAnalogToDigitalConverterSamplesData

\brief The output radar data for Arbitrary analog-to-digital converter 
samples.

Data are stored as multi-dimensional array of complex values or real
values, depending of the \c is_complex_valued flag of the message.
The physical dimensions are [TX, RX, Sample] and
so the data contains:

    numberOfTX x numberOfRX x numberOfSamples complex numbers

 or equivalently

    2 x numberOfTX x numberOfRX x numberOfSamples real numbers

If the complex data is read sequentially, the outermost loop corresponds
to the TX dimension, then RX dimension, then Sample dimension which is the
innermost.

\note Arbitrary waveform is delivered as a beta feature 
in the current release.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| data | [float](#float) | repeated | The multi-dimensional array. |
| number_of_samples | [int32](#int32) |  | The number of samples |
| rx_identifiers | [int32](#int32) | repeated | Receiver antennas identifiers. |
| tx_identifiers | [int32](#int32) | repeated | Transmitter antennas identifiers. |
| is_complex_valued | [bool](#bool) |  | Indicates whether values are defined as complex numbers. |
| multiplexing | [Multiplexing](#multiplexing) |  | Multiplexing type. |

### ArbitraryFrequencyPulseResponseData

\brief The radar output data for Arbitrary frequency pulse response.

Data are stored as multi-dimensional array of complex values, with
interleaved real and imaginary parts: real1, imag1, real2, imag2 etc.
The physical dimensions are [TX, RX, Sample] and so the
data contains:

    numberOfTX x numberOfRX x numberOfSamples complex numbers

 or equivalently

    2 x numberOfTX x numberOfRX x numberOfSamples real numbers

If the complex data is read sequentially, the outermost loop corresponds to
the TX dimension, then RX dimension, then Sample dimension which is 
the innermost.

\note Arbitrary waveform is delivered as a beta feature 
in the current release.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| data | [float](#float) | repeated | The multi-dimensional array. |
| number_of_samples | [int32](#int32) |  | The number of samples. |
| rx_identifiers | [int32](#int32) | repeated | Receiver antennas identifiers. |
| tx_identifiers | [int32](#int32) | repeated | Transmitter antennas identifiers. |
| multiplexing | [Multiplexing](#multiplexing) |  | Multiplexing type. |

### Domain

\brief A radar data domain. 

Indicates how to retrieve information from the float array of
the containing data message.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| size | [int32](#int32) |  | Number of samples for this domain. |
| min_value | [double](#double) |  | Minimum value in the samples. |
| max_value | [double](#double) |  | Maximum value in the samples. |

### FrequencyPulseResponseData

\brief The radar output data for frequency pulse response. 

Data are stored as multi-dimensional array of complex values, with
interleaved real and imaginary parts: real1, imag1, real2, imag2 etc.
The physical dimensions are [TX, RX, pulse time, frequency] and so the
data contains:

    numTX x numRX x numPulseTime x numFrequencies complex numbers

 or equivalently

    2 x numTX x numRX x numPulseTime x numFrequencies real numbers

If the complex data is read sequentially, the outermost loop corresponds to
the TX dimension, then RX, then pulse time, and then frequencies which is 
the innermost.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| data | [float](#float) | repeated | The multi-dimensional array. |
| frequency_domain | [Domain](#domain) |  | The number of frequency samples and the min/max values in the samples. |
| pulse_time_domain | [Domain](#domain) |  | The number of pulse time samples and the min/max values in the samples. |
| rx_identifiers | [int32](#int32) | repeated | Receiver antennas identifiers. |
| tx_identifiers | [int32](#int32) | repeated | Transmitter antennas identifiers. |
| multiplexing | [Multiplexing](#multiplexing) |  | Multiplexing type. |

### ModeOutputData

\brief The message providing radar output data for a given mode.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| range_doppler_response | [RangeDopplerResponseData](#rangedopplerresponsedata) |  | \c RangeDopplerResponseData. |
| frequency_pulse_response | [FrequencyPulseResponseData](#frequencypulseresponsedata) |  | \c FrequencyPulseResponseData. |
| analog_to_digital_converter_samples | [AnalogToDigitalConverterSamplesData](#analogtodigitalconvertersamplesdata) |  | \c AnalogToDigitalConverterSamplesData. |
| mode_identifier | [int32](#int32) |  | The mode identifier. |
| tx_waveform | [TxWaveformData](#txwaveformdata) |  | \c TxWaveformData. |
| arbitrary_frequency_pulse_response | [ArbitraryFrequencyPulseResponseData](#arbitraryfrequencypulseresponsedata) |  | \c ArbitraryFrequencyPulseResponseData. |
| arbitrary_analog_to_digital_converter_samples | [ArbitraryAnalogToDigitalConverterSamplesData](#arbitraryanalogtodigitalconvertersamplesdata) |  | \c ArbitraryAnalogToDigitalConverterSamplesData. |
| response_to_tx_waveform_map | [uint32](#uint32) | repeated | Response to Tx waveform map.<br><br>List of indexes mapping the response data to the Tx waveform data.<br> - The position in the list represents the sample index in the <br> response data.<br> - The value in the list represents the sample index in the Tx <br> waveform data. |

### RadarOutputData

\brief The radar output data for all modes.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| modes | [ModeOutputData](#modeoutputdata) | repeated | An array of \c ModeOutputData. |

### RangeDopplerResponseData

\brief The radar range doppler output data.

Data are stored as multi-dimensional array of complex values, with
interleaved real and imaginary parts: real1, imag1, real2, imag2 etc.
The physical dimensions are [TX, RX, velocity, range] and so the data
contains:

    numTX x numRX x numVelocities x numRanges complex numbers

 or equivalently

    2 x numTX x numRX x numVelocities x numRanges real numbers

If the complex data is read sequentially, the outermost loop corresponds to
the TX dimension, then RX, then velocity, and then range which is the
innermost.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| data | [float](#float) | repeated | The multi-dimensional array. |
| range_domain | [Domain](#domain) |  | The number of range samples and the min/max values in the samples. |
| velocity_domain | [Domain](#domain) |  | The number of velocity samples and the min/max values in the samples. |
| rx_identifiers | [int32](#int32) | repeated | Receiver antennas identifiers. |
| tx_identifiers | [int32](#int32) | repeated | Transmitter antennas identifiers. |
| multiplexing | [Multiplexing](#multiplexing) |  | Multiplexing type. |

### TxWaveformData

\brief The radar output data for the transmitted waveform.

Data are stored as a multi-dimensional array of values.
The physical dimensions are [pulses or chirps, samples, values per sample]
and so the data contains:

    numPulsesOrChirps x numSamples x  numValuesPerSample numbers


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| data | [double](#double) | repeated | The multi-dimensional array. |
| tx_identifiers | [int32](#int32) | repeated | Transmitter antennas identifiers. |
| number_of_values_per_sample | [int32](#int32) |  | Number of values for each waveform sample.<br><br>Current implementation will provide nine values for each sample,<br>organized as follows:<br> - Pulse or chirp index (0-based): the pulse/chirp position within<br> the pulse/chirp sequence.<br> - Sample index (0-based): the sample position within a pulse/chirp.<br> - Transmitter index (0-based position): the transmitter position in<br> the tx_identifiers list.<br> - Simulation sample time: the sample time relative to the simulation<br> update time. Expressed in seconds (s).<br> - CPI sample time: the sample time relative to the center of CPI.<br> Expressed in seconds (s).<br> - Chirp sample time: the sample time relative to the center of chirp.<br> Expressed in seconds (s). Always zero for a pulse-Doppler waveform.<br> - Sample frequency: the frequency of sample in hertz (Hz).<br> - Amplitude: the relative broadcast amplitude of the sample,<br> currently always unity (1).<br> - Phase: the phase of the broadcast sample relative to the signal fed<br> to rx mixer, currently always zero (0).<br><br>All values are double-precision, including notionally integer values<br>(i.e., indices).<br>The number of values per sample could increase in future versions. |
| number_of_samples | [int32](#int32) |  | Number of samples for each pulse or chirp. |
| number_of_pulses_or_chirps | [int32](#int32) |  | Number of pulses or chirps in the waveform. |


### Multiplexing

\brief Represents the way a radar uses its TX antennas.

| Name | Number | Description |
| ---- | ------ | ----------- |
| INTERLEAVED | 0 | Interleaved multiplexing. |
| SIMULTANEOUS | 1 | Simultaneous multiplexing.<br><br>\note Simultaneous multiplexing is delivered as a beta feature <br>in the current release. |



## avx/vss/sensor_data/sensor_data.proto



### CameraData

\brief A block containing a set of camera data.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| entries | [CameraDataEntry](#cameradataentry) | repeated | List of \c CameraDataEntry. |

### CameraDataEntry

\brief A single formatted camera data.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| image_data | [CameraImageData](#cameraimagedata) |  | Image produced by the camera sensor. |
| ground_truth_data | [CameraGroundTruthData](#cameragroundtruthdata) |  | Ground truth data produced for the camera sensor. |
| bounding_box_2d | [BoundingBox2D](#boundingbox2d) |  | 2D Bounding box produced. |
| camera_lens_output | [CameraLensOutput](#cameralensoutput) |  | Spectral irradiance map, which is the lens output of the camera sensor. |
| camera_custom_data_output | [CameraImageData](#cameraimagedata) |  | Custom data, which is custom data output of the camera sensor. |

### LidarData

\brief A block containing a set of formatted lidar data.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| entries | [LidarDataEntry](#lidardataentry) | repeated | List of \c LidarDataEntry. |

### LidarDataEntry

\brief A single formatted lidar data.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| point_cloud_data | [PointCloudData](#pointclouddata) |  | Point cloud data |
| waveform_data | [WaveformData](#waveformdata) |  | Waveform data |
| contribution_data | [ContributionData](#contributiondata) |  | Contribution data |
| lens_output_data | [LensOutputData](#lensoutputdata) |  | %Lens Output data |

### RadarData

\brief A block containing a set of formatted radar data.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| entries | [RadarDataEntry](#radardataentry) | repeated | List of \c RadarDataEntry. |

### RadarDataEntry

\brief A single formatted radar data


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| radar_data | [RadarOutputData](#radaroutputdata) |  | \c RadarOutputData |

### SensorData

\brief Defines the structure of the data which was produced by a single
sensor for one simulation step.

Time stamp and type of sensor data produced.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| time_stamp | [google.protobuf.Duration](#duration) |  | The simulation time stamp in which the data was produced. |
| camera_data | [CameraData](#cameradata) |  | \c CameraData. |
| lidar_data | [LidarData](#lidardata) |  | \c LidarData. |
| radar_data | [RadarData](#radardata) |  | \c RadarData. |




## avx/vss/simulation/configuration.proto



### AssetInfo

\brief Describes one asset.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| vss_identity | [vss.ObjectIdentifier](#objectidentifier) |  | The unique identifier of the asset.<br><br>\note The identifier is case sensitive. |
| resource | [vss.ResourceIdentifier](#resourceidentifier) |  | The path to the asset file or the identifier of the uploaded asset. |

### Configuration

\brief %Configuration message containing all parameters needed to
 load resources in AVX.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| scene | [SceneInfo](#sceneinfo) |  | \c SceneInfo. |
| deploy_parameters | [EndPointRange](#endpointrange) |  | **Deprecated.** The infrastructure deploy parameters.<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using DeployConfiguration instead. |
| deploy_configuration | [DeployConfiguration](#deployconfiguration) |  | The infrastructure deploy parameters. |
| simulation_parameters | [SimulationParameters](#simulationparameters) |  | The simulation parameters. |
| sensors | [SensorConfig](#sensorconfig) |  | \c SensorConfig. |
| lighting_system_configuration | [LightingSystemConfiguration](#lightingsystemconfiguration) |  | The lighting system configuration of the ego vehicle. <br><br>\note Multiple lighting systems can be associated with the ego vehicle,<br>but only one can be set as active. When this parameter <br>is not set, the vehicle lighting is based on the tags defined in<br>the vehicle asset. |
| lighting_system | [LightingSystem](#lightingsystem) |  | **Deprecated.** The lighting system configuration of the ego vehicle.<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using LightingSystemConfiguration instead. |
| ego_vehicle_identity | [vss.ObjectIdentifier](#objectidentifier) |  | The ego vehicle's unique identifier (the vehicle instance on which the<br>sensor configuration will be attached). |

### LightingSystem

\brief Describes a lighting system with its identifier and either a
data buffer or the identifier of the uploaded resource.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| identifier | [vss.ObjectIdentifier](#objectidentifier) |  | The unique identifier of the lighting system. |
| lighting_system_data | [bytes](#bytes) |  | The encapsulated byte array. |
| resource | [vss.ResourceIdentifier](#resourceidentifier) |  | The identifier of the uploaded lighting system. |

### LightingSystemConfiguration

Contains all the lighting systems associated with the ego vehicle, as well as
the active lighting system.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| lighting_systems | [LightingSystem](#lightingsystem) | repeated | The list of all lighting systems associated with the ego vehicle. |
| active_lighting_system | [vss.ObjectIdentifier](#objectidentifier) |  | The lighting system that will be set to active.<br><br>\note If this value is not set, the first lighting system associated with<br>the ego vehicle is set as active. |

### SceneInfo

\brief Contains all components that make up a scene: the assets and the 
track.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| assets | [AssetInfo](#assetinfo) | repeated | The list of all assets included in the scene. |
| track | [vss.ResourceIdentifier](#resourceidentifier) |  | The path to the track file or the identifier of the uploaded track. |

### SensorConfig

\brief Describes a binary sensor configuration data.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| sensor_configuration | [bytes](#bytes) |  | The encapsulated byte array.<br><br>\note We chose to have a supertype so that it may evolve in the future <br>with lower impact. |




## avx/vss/simulation/deploy_parameters.proto



### DeployConfiguration

\brief Describes the parameters used to configure AVX deployment.

AVX is designed to be distributed over several nodes or machines of 
the same operating system.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| local_nodes | [LocalNodes](#localnodes) |  | Parameters used to spawn the AVX local processes. |
| deploy_hosts | [DeployHost](#deployhost) | repeated | Parameters used to spawn the AVX remote processes. |

### DeployHost

\brief Defines the deploy nodes on a remote host.

A deploy host is identified by its IPv4 address.

\note A deploy host can contain more than one deploy node.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| address | [string](#string) |  | IPv4 host address used to spawn the AVX processes. |
| deploy_nodes | [DeployNode](#deploynode) | repeated | List of deploy nodes on this host. |
| resource_manager_port | [google.protobuf.Int32Value](#int32value) |  | The TCP port used to communicate with resource manager node. |
| gpu_identifiers | [GpuIdentifier](#gpuidentifier) | repeated | The identifiers of the GPUs that are available on this deploy host.<br><br>\note The user is responsible for the validity of the identifiers. |
| data_access_server_port | [google.protobuf.Int32Value](#int32value) |  | The TCP port used to communicate with the data access server (optional). |

### DeployNode

\brief Defines the deploy node parameters.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| node_id | [string](#string) |  | A user-defined identifier for the node.<br>This identifier must be unique to the node.<br><br>\note The identifier is case-sensitive and can be any string with<br>no character limit. |
| port | [google.protobuf.Int32Value](#int32value) |  | The TCP port used to communicate with the node. |

### EndPointRange

\brief Describes the parameters used to configure AVX deployment.

AVX is designed to be distributed over several nodes or machines of 
the same operating system. 

\warning This message is deprecated and will be removed. It has been 
replaced by the DeployConfiguration message.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| host | [string](#string) |  | **Deprecated.** Host used to spawn the AVX processes.<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using DeployConfiguration.local_nodes <br>instead. |
| min_port | [int32](#int32) |  | **Deprecated.** The first TCP port used to communicate.<br><br>AVX allocates ports to communicate with different<br>processes starting from this min_port value.<br><br>\note The value must be greater than 1024.<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using DeployConfiguration.local_nodes <br>instead. |
| max_port | [int32](#int32) |  | **Deprecated.** The last TCP port used to communicate.<br><br>AVX allocates ports to communicate with different<br>processes until this last port.<br><br>\note The value must be greater than the min_port value.<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using DeployConfiguration.local_nodes <br>instead. |

### GpuIdentifier

\brief Represents an identifier for a GPU


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| name | [string](#string) |  | A user-defined name for the GPU.<br>This identifier must be unique.<br><br>\note The identifier is case-sensitive and can be any string with<br>no character limit. |
| index | [string](#string) |  | The index number of the GPU.<br><br>\note The GPU index might not be consistent between PC reboots. For<br>consistency, it is recommended to use the PCI bus ID or UUID instead. <br>For more details, please see the user documentation. |
| bus_id | [string](#string) |  | The PCI bus identifier of the GPU.<br><br>\note The PCI bus identifier must have the format a:b:c.d with<br>a = domain ID, b = bus ID, c = device ID, d = function ID and each<br>represented as base-16 number with 1 to 8 digits. |
| uuid | [string](#string) |  | The UUID of the GPU.<br><br>\note The UUID must be a string starting with an upper-case 'GPU' <br>followed by five base-16 number blocks separated with a hyphen. The<br>blocks must have the following amount of digits: 8, 4, 4, 4 and 12.<br>Example: GPU-12345678-1234-1234-1234-123456789abc |

### LocalNodes

\brief The deploy parameters of the local workstation.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| min_port | [google.protobuf.Int32Value](#int32value) |  | The first TCP port used to communicate with local nodes.<br><br>AVX allocates ports to communicate with different<br>processes starting from this min_port value.<br><br>\note The value must be greater than 1024. |
| max_port | [google.protobuf.Int32Value](#int32value) |  | The last TCP port used to communicate with local nodes.<br><br>AVX allocates ports to communicate with different<br>processes until this last port.<br><br>\note The value must be greater than the min_port value. |
| gpu_identifiers | [GpuIdentifier](#gpuidentifier) | repeated | The identifiers of the GPUs that are available on the local host.<br><br>\note The user is responsible for the validity of the identifiers. |




## avx/vss/simulation/simulation.proto





### Simulation

\brief This service provides the simulation control procedures.

\note The AVX state machine (simulation logic) must be considered
when using simulation control procedures. Procedures that
are not consistent with current AVX state will end in ERROR.

| Method Name | Request Type | Response Type | Description |
| ----------- | ------------ | ------------- | ------------|
| Load | [Configuration](#configuration) | [.vss.Status](#status) | Loads AVX with a track, a list of assets, some simulation parameters,<br>a sensor configuration, a lighting system (optional), some deployment<br>parameters and the ID of the ego vehicle (the vehicle instance on which<br>the sensor configuration will be attached). |
| Initialize | [WorldUpdate](#worldupdate) | [.vss.Status](#status) | Sets the initial position/orientation/states of all components of the <br>world and changes AVX state to RUNNING. |
| Update | [WorldUpdate](#worldupdate) | [.vss.Status](#status) | Applies a world model update to AVX. |
| Stop | [.google.protobuf.Empty](#empty) | [.vss.Status](#status) | Changes AVX state from RUNNING to LOADED. |
| Unload | [.google.protobuf.Empty](#empty) | [.vss.Status](#status) | Unloads the simulation and switches AVX back to STARTED state.<br><br>\note This command is used to restart a simulation without having to <br>restart AVX. |
| Kill | [.google.protobuf.Empty](#empty) | [.vss.Status](#status) | Sends a signal to end the AVX program properly. Closes the Grpc server. |


## avx/vss/simulation/simulation_parameters.proto



### AutomaticBatching

\brief Defines the automatic batching configuration.

\note With the automatic batching method, the number of batches on rays and 
on rx channels are computed by the system taking into account the 
specified two constraints. 
There are two possibilities for the second constraint according to your 
needs: 
To use the default GPU, set the gpu_memory_quota. 
To use any other GPU or several GPUs, set the gpu_quotas.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| max_number_of_ray_batches | [int32](#int32) |  | First constraint: the upper bound on the automatically computed number <br>of ray batches. |
| gpu_memory_quota | [double](#double) |  | Second constraint, option 1: the max fraction (quota) of the total <br>GPU memory that can be used. The default GPU (whose index is 0) will be <br>used. |
| gpu_quotas | [AutomaticBatching.GpuQuotasEntry](#gpuquotasentry) | repeated | Second constraint, option 2: the max fraction (quota) of the total memory <br>of the specified GPU that can be used.<br><br>Key [string]: The GPU name.<br><br>Value [double]: The max fraction of the GPU memory that can be used.<br><br>\note The GPU names must correspond to the GpuIdentifier names specified <br>in the deploy parameters. |

### AutomaticBatching-GpuQuotasEntry




| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| key | [string](#string) |  |  |
| value | [double](#double) |  |  |

### CameraGroundTruthParameters

\brief Defines the types of ground truth output data the 
physics-based camera simulation will generate.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| generate_depth_map | [bool](#bool) |  | Activation of the depth map production.<br><br>A depth map indicates for each pixel the distance of the associated point <br>relative to the camera sensor's mounting position.<br><br>Default value: false |
| generate_optical_flow | [bool](#bool) |  | Activation of the optical flow production.<br><br>The optical flow indicates for each pixel the linear speed of the <br>associated point relative to the camera sensor's mounting position.<br><br>Default value: false |
| generate_pixel_segmentation | [bool](#bool) |  | Activation of the pixel segmentation production.<br><br>The pixel segmentation gives a color to each pixel based on the object<br>it belongs to.<br><br>Default value: false |
| generate_2d_bounding_boxes | [bool](#bool) |  | Activation of the 2D bounding boxes production.<br><br>2D bounding corresponds to the projection of 3D bounding box on the<br>camera image plane.<br><br>Default value: false |

### CartesianGrid

\brief Defines the Cartesian grid.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| horizontal_grid_points | [int32](#int32) |  | The number of horizontal squares in the grid. |
| vertical_grid_points | [int32](#int32) |  | The number of vertical squares in the grid. |

### DataAccessSettings

\brief Defines the mechanisms for accessing and managing sensor data.
It supports configurations for storing data either on disk or 
in shared memory.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| recording_format | [RecordingFormat](#recordingformat) |  | Specifies the format and details for dumping sensor data to disk.<br>The RecordingFormat should be selected based on the desired format.<br>See the RecordingFormat documentation for available options.<br><br>\note Optional field. If not set, sensor data is not written to disk. |
| shared_memory_access | [google.protobuf.BoolValue](#boolvalue) |  | Specifies whether or not the output data should be stored in shared<br>memory.<br><br>Default value: true<br><br>\note Optional field. If set to true or if not set, storage in shared<br>memory is enabled, and data can be accessed via a notification-based<br>mechanism. |
| remote_direct_memory_access | [RemoteDirectMemoryAccess](#remotedirectmemoryaccess) |  | \note Data access using Remote Direct Memory Access (RDMA) technology<br> is delivered as an experimental feature in the current release. |

### DisplayInformation

\brief Defines the display settings of a camera sensor.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| top_left_corner_position | [TopLeftCornerPosition](#topleftcornerposition) |  | Describes the position of the top left corner of the rendering window. |
| display_only | [bool](#bool) |  | Activation of the Display Only mode.<br><br>When the Display Only mode is activated (parameter set to true),<br>the camera data are only displayed in the rendering window. <br>No data is recorded (neither in the shared memory nor dumped on disk)<br>and the recording_format parameter is ignored.<br><br>When the Display Only mode is off (parameter set to false, which is the <br>default value), camera output data are both generated in shared memory <br>and displayed in the rendering window.<br><br>Default value: false |

### Grid

\brief Describes the type of lidar sensor grid.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| cartesian_grid | [CartesianGrid](#cartesiangrid) |  | The Cartesian grid.<br><br>\note Cartesian grid applies to flashing lidar only. |
| polar_grid | [PolarGrid](#polargrid) |  | The polar grid.<br><br>\note Polar grid applies to rotating lidar only. |

### LidarSimulation

\brief Describes simulation parameters for a lidar.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| waveform | [bool](#bool) |  | Activation of the waveform output production by the lidar.<br><br>Default value: false |
| contribution | [bool](#bool) |  | Activation of the contribution output production by the lidar.<br><br>Default value: false |
| grid | [Grid](#grid) |  | The lidar ray-tracing grid. |
| number_of_batches | [google.protobuf.Int32Value](#int32value) |  | The number of batches.<br><br>Default value: 1 |
| gpu_name | [string](#string) |  | The GPU name that must be used for the simulation of this <br>lidar sensor.<br><br>\note The GPU name must correspond to a GpuIdentifier name specified in<br>the deploy parameters.<br> <br>\note Optional field. If not set, the default GPU (whose index is 0)<br>will be used. |
| use_rgb_diffuse | [bool](#bool) |  | Use RGB diffuse parameters in the simulation of this lidar sensor.<br><br>Default value: false<br><br>\note Use of RGB diffuse parameters is delivered as a beta feature in<br>the current release. |

### LightingSystemParameters

\brief Contains lighting system simulation parameters.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| sampling_rate | [double](#double) |  | Angular sampling used on the lighting system light sources <br>when computing the rendering.<br><br>Unit: degrees<br><br>Range: [ 0.05, 57 ]<br><br>Default value: 0.05 |

### ManualBatching

\brief Defines the manual batching configuration.

\note With the manual batching method, the number of batches for rays and 
rx channels must be specified.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| number_of_ray_batches | [int32](#int32) |  | The number of batches on casted rays: applies to all radar modes. |
| rx_batching | [RxBatching](#rxbatching) | repeated | The batching on rx channels. |
| gpu_by_modes | [ManualBatching.GpuByModesEntry](#gpubymodesentry) | repeated | The names of the GPU that must be used for the simulation of the <br>modes of this radar sensor.<br><br>Key [int32]: The mode id.<br><br>Value [string]: The GPU name.<br><br>\note The GPU names must correspond to the GpuIdentifier names specified<br> in the deploy parameters. |

### ManualBatching-GpuByModesEntry




| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| key | [int32](#int32) |  |  |
| value | [string](#string) |  |  |

### OutputSplitting

\brief Defines the output data splitting configuration.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| radar_output_splitting | [RadarOutputSplitting](#radaroutputsplitting) |  | The radar output splitting configuration. |

### PbCameraSimulation

\brief Describes the simulation parameters for a physics-based camera.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| rendering_parameters | [RenderingParameters](#renderingparameters) |  | The rendering engine parameters. |
| camera_ground_truth_parameters | [CameraGroundTruthParameters](#cameragroundtruthparameters) |  | **Deprecated.** Activation of ground truth output production that can be used to<br>test or train a perception algorithm.<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using <br>RenderingParameters.RealTimeParameters.camera_ground_truth_parameters<br> instead. |
| gpu_name | [string](#string) |  | The GPU name that must be used for the simulation of this <br>camera sensor.<br><br>\note The GPU name must correspond to an existing name set in<br>the GpuIdentifier in a deploy or local host in the deploy configuration.<br><br>\note Optional field. If not set, the default GPU (whose index is 0)<br>will be used. |

### PolarGrid

\brief Defines the polar grid.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| radial_grid_points | [int32](#int32) |  | The number of radial segments. |
| angular_grid_points | [int32](#int32) |  | The number of angular segments. |
| has_central_point | [bool](#bool) |  | Indicates whether or not an on-axis ray (point of emission) must be <br>added to the center of the grid.<br><br>Default value: false |

### RadarDebugViewParameters

\brief Describes the parameters for the radar's debug view.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| color_mode | [ColorMode](#colormode) |  | The color mode of the debug view images. |
| image_width | [google.protobuf.Int32Value](#int32value) |  | The width of the debug view images.<br><br>Range: ] 0, int32 max ]<br><br>Default value: 1024<br><br>\note The debug view image is square (width = height). |
| background_gray_level | [google.protobuf.Int32Value](#int32value) |  | The gray level of the debug view image's background.<br><br>Range: [ 0, 255 ]<br><br>Default value: 128 |
| enable_material_shading | [google.protobuf.BoolValue](#boolvalue) |  | Enables or disables the shading of the materials in the output images <br>of the debug view with the COATING color mode.<br>Shading materials eases image interpretation by humans.<br> <br>\note This parameter only applies to debug view images with the COATING <br>color mode. Its value will not be considered if any other color mode is <br>used.<br><br>Default value: false |
| oversample | [google.protobuf.DoubleValue](#doublevalue) |  | The rasterization density when rasterizing the triangles to fill<br>image pixels.<br><br>Range: ] 0, double max ]<br><br>Default value: 1.0<br><br>\note It is recommended to start with 1.0 and increase as needed to <br>achieve the desired image quality. |

### RadarGridSampling

\brief Radar grid sampling specifies the global sampling and the adaptive
sampling to be applied to the scene.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| global_sampling | [RadarGridSamplingParameters](#radargridsamplingparameters) |  | Global sampling defining the default sampling to be applied to the scene. |
| adaptive_sampling | [RadarGridSampling.AdaptiveSamplingEntry](#adaptivesamplingentry) | repeated | The tag-sampling mapping table for adaptive sampling which assigns ray<br>spacing values to tagged objects.<br><br>\note If a tag is not associated to any object in the scene, the simulation<br>will stop with an error.<br><br>\note Here, the expected text string is the CamelCase form of the tag name<br>in Asset Preparation Editor. For example:<br> - RoadSign for Road Sign, StreetLight for Street Light.<br> - Body, SteeringWheel for Steering Wheel.<br>Be aware of the following two exceptions: SimulationObject should be used <br>instead of Object, Indicator should be used instead of Turn Indicator.<br>For custom tags, the expected text string is the name of the tag as <br>it is written in the Editor.<br><br>\note For tags belonging to the same hierarchy of objects, the ray<br>spacing value assigned to a child-node tag must be less than or equal to<br>that of the parent-node tag. If the ray spacing value of <br>the child-node tag is greater than that of the parent-node tag, <br>it will be be lowered to match the ray spacing value of the parent-node<br>tag. |

### RadarGridSampling-AdaptiveSamplingEntry




| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| key | [string](#string) |  |  |
| value | [RadarGridSamplingParameters](#radargridsamplingparameters) |  |  |

### RadarGridSamplingParameters

\brief Radar grid sampling parameters, which consist of the ray spacing
parameter.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| ray_spacing | [double](#double) |  | The ray spacing expressed as the distance between adjacent rays measured at<br>100 m from the source.<br><br>Unit: meter (m)<br><br>Range: ] 0, double max ] |

### RadarOutputSplitting

\brief Defines the radar output data splitting configuration.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| radar_output_splitting_level | [RadarOutputSplittingLevel](#radaroutputsplittinglevel) |  | The radar output splitting level. |

### RadarSimulation

\brief Describes the simulation parameters for a radar and, optionally,
the type of batching method.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| number_of_ray_reflections | [int32](#int32) |  | The maximum number of ray bounces (reflections) on the scene's objects<br>before the ray is forced to return to the sensor.<br><br>\note The limit applies to each individual ray. |
| number_of_ray_transmissions | [int32](#int32) |  | The maximum number of transmissions on the scene's objects before<br>the ray is forced to return to the sensor.<br><br>\note The limit applies to each individual ray. |
| ray_density | [double](#double) |  | **Deprecated.** The linear ray density per radar wavelength (at max distance of 100 m).<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using grid_sampling instead. |
| grid_sampling | [RadarGridSampling](#radargridsampling) |  | The sampling of the grid.<br><br>\note RadarGridSampling parameters are delivered as a beta feature in<br>the current release. |
| manual_batching | [ManualBatching](#manualbatching) |  | The configuration of the manual batching.<br><br>\note Optional field. By default, the sensor execution is not batched. |
| automatic_batching | [AutomaticBatching](#automaticbatching) |  | The configuration of the automatic batching.<br><br>\note Optional field. By default, the sensor execution is not batched. |
| tx_waveform_report | [bool](#bool) |  | Activation of the tx waveform output generation by the radar.<br><br>Default value: false |
| ego_vehicle_emission_blockage | [bool](#bool) |  | Indicates whether or not the Ego vehicle geometry will be<br>considered in calculations upon the emission of the ray's first bounce.<br><br>When this parameter is set to true, the ego vehicle geometry<br>is considered in calculations upon the emission of the ray's first <br>bounce.<br><br>When this parameter is set to false (which is the default value),<br>the ego vehicle geometry is not considered in calculations upon the <br>emission of the ray's first bounce.<br><br>Default value: false |
| debug_view_parameters | [RadarDebugViewParameters](#radardebugviewparameters) |  | Parameters for the debug view. <br><br>Optional field. If not set, the debug view is disabled. |
| max_ray_path_length_by_mode | [RadarSimulation.MaxRayPathLengthByModeEntry](#maxraypathlengthbymodeentry) | repeated | The maximal length for the ray path per radar mode.<br><br>Key [int32]: The mode id.<br><br>Value [double]: The maximal length for the ray path.<br><br>Unit: meters (m)<br><br>Range: ] 0, 2* max_path_length [<br><br>Default value: 200<br><br>\note Features with total path length greater than twice the max ray path<br>length, including the path back to the radar, will be excluded.<br><br>\note This parameter only applies to radars with arbitrary waveform.<br><br>\note Arbitrary waveform is delivered as a beta feature <br>in the current release. |
| max_velocity_by_mode | [RadarSimulation.MaxVelocityByModeEntry](#maxvelocitybymodeentry) | repeated | The maximal velocity for each radar mode. <br><br>Key [int32]: The mode id.<br><br>Value [double]: The maximal velocity.<br><br>Unit: meters per second (m/s)<br><br>Range: ] 0, double max[<br><br>Default value: 75<br><br>\note Features with (absolute value of) relative velocity greater than<br>the maximal velocity will be excluded.<br><br>\note This parameter only applies to radars with arbitrary waveform.<br><br>\note Arbitrary waveform is delivered as a beta feature <br>in the current release. |

### RadarSimulation-MaxRayPathLengthByModeEntry




| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| key | [int32](#int32) |  |  |
| value | [double](#double) |  |  |

### RadarSimulation-MaxVelocityByModeEntry




| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| key | [int32](#int32) |  |  |
| value | [double](#double) |  |  |

### RecordingFormat

\brief Defines the format for recording the sensor's outputs.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| camera_recording_format | [vss.CameraDataFormat](#cameradataformat) |  | Format for recording camera output.<br><br>Can be one of the following: RAW, BMP, GIF, JPEG, or PNG. |
| radar_recording_format | [vss.OutputFormat](#outputformat) |  | Format for recording radar output. |
| lidar_recording_format | [vss.OutputFormat](#outputformat) |  | Format for recording lidar output. |

### RemoteDirectMemoryAccess

\brief Data access using Remote Direct Memory Access (RDMA) technology
is delivered as an experimental feature in the current release.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| buffer_size | [int32](#int32) |  |  |
| sender_address | [string](#string) |  |  |
| sender_port | [google.protobuf.Int32Value](#int32value) |  |  |
| sender_backchannel_port | [google.protobuf.Int32Value](#int32value) |  |  |

### RenderingParameters

\brief Sets the rendering engine parameters for a camera.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| camera_near_plane | [google.protobuf.FloatValue](#floatvalue) |  | **Deprecated.** The camera near plane value.<br><br>Unit: meters (m)<br><br>Range: ] 0, camera_far_plane [<br><br>Default value: 0.1<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using RealTimeParameters.camera_near_plane instead. |
| camera_far_plane | [google.protobuf.FloatValue](#floatvalue) |  | **Deprecated.** The camera far plane.<br><br>Unit: meters (m)<br><br>Range: ] CameraNearPlane, float max ]<br><br>Default value: 10000.0<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using RealTimeParameters.camera_far_plane instead. |
| shadow_quality | [Qualities](#qualities) |  | **Deprecated.** The camera shadow quality.<br><br>Default value: EXTREME<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using RealTimeParameters.shadow_quality instead. |
| texture_quality | [Qualities](#qualities) |  | **Deprecated.** The camera texture quality.<br><br>Default value: EXTREME<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using RealTimeParameters.texture_quality instead. |
| borderless | [google.protobuf.BoolValue](#boolvalue) |  | Indicates whether or not the rendering window is borderless.<br><br>Default value: false |
| antialiasing_factor | [google.protobuf.FloatValue](#floatvalue) |  | **Deprecated.** The camera antialiasing factor.<br><br>Range: [ 1.0, 4.0 ]<br><br>Default value: 1.0<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using RealTimeParameters.antialiasing_factor instead. |
| vertical_sync | [google.protobuf.BoolValue](#boolvalue) |  | Vertical synchronization between the rendering frequency of the Display <br>and the frame rate of the screen where the rendering window is located.<br><br>Default value: false |
| enable_alpha_channel | [google.protobuf.BoolValue](#boolvalue) |  | Enables or disables the alpha channel in the camera output.<br><br>Default value: true<br><br>\note The values for the alpha channel are not used and are filled with <br>default values. |
| enable_asynchronous_readback | [bool](#bool) |  | Enables or disables asynchronous GPU readback.<br><br>Default value: false<br><br>\note Asynchronous GPU readback is delivered<br>as a beta feature in the current release. |
| real_time_parameters | [RenderingParameters.RealTimeParameters](#realtimeparameters) |  | Camera simulation parameters for real time rendering. |

### RenderingParameters-RealTimeParameters

\brief Sets the camera simulation parameters for real time rendering.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| camera_near_plane | [google.protobuf.FloatValue](#floatvalue) |  | The camera near plane value.<br><br>Unit: meters (m)<br><br>Range: ] 0, camera_far_plane [<br><br>Default value: 0.1 |
| camera_far_plane | [google.protobuf.FloatValue](#floatvalue) |  | The camera far plane.<br><br>Unit: meters (m)<br><br>Range: ] CameraNearPlane, float max ]<br><br>Default value: 10000.0 |
| shadow_quality | [Qualities](#qualities) |  | The camera shadow quality.<br><br>Default value: EXTREME |
| texture_quality | [Qualities](#qualities) |  | The camera texture quality.<br><br>Default value: EXTREME |
| antialiasing_factor | [google.protobuf.FloatValue](#floatvalue) |  | The camera antialiasing factor.<br><br>Range: [ 1.0, 4.0 ]<br><br>Default value: 1.0 |
| camera_ground_truth_parameters | [CameraGroundTruthParameters](#cameragroundtruthparameters) |  | Activation of the production of ground truth outputs.<br><br>Ground truth output data can be used to test or train a perception <br>algorithms.<br><br>\note Optional field. If not set, no ground truth output is generated. |

### RxBatching

\brief Sets the batching on rx channels.

\note The number of batches is set, and therefore applies, independently
for each radar mode.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| mode_id | [int32](#int32) |  | The id of the mode to which rx batching is applied. |
| number_of_rx_batches | [int32](#int32) |  | The number of batches on rx channels. |

### SensorParameters

\brief Contains the simulation parameters for a given sensor id.

\note If the type of sensor is not consistent with the sensor configuration,
it will cause an error.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| identifier | [string](#string) |  | The unique identifier of the sensor as defined in the sensor<br>configuration. |
| recording_format | [RecordingFormat](#recordingformat) |  | **Deprecated.** Indicates if the sensor must dump its outputs to disk.<br><br>\note Optional field. If not set, no sensor data will be dumped <br>to disk.<br><br>\warning This field is marked as deprecated and might be removed<br>in later versions. Consider using DataAccess instead. |
| display | [DisplayInformation](#displayinformation) |  | Indicates if the camera output must be displayed on the <br>screen in a dedicated rendering window.<br><br>The resolution of the rendering window is the one<br>defined in the sensor configuration.<br><br>\note Optional field. If not set, the camera outputs <br>will not be displayed on the screen.<br><br>\note Only applicable to camera sensors. Ignored for other sensors. |
| radar_simulation | [RadarSimulation](#radarsimulation) |  | Specific parameters for a radar. |
| lidar_simulation | [LidarSimulation](#lidarsimulation) |  | Specific parameters for a lidar. |
| pb_cam_simulation | [PbCameraSimulation](#pbcamerasimulation) |  | Specific parameters for a physics-based camera. |
| thermal_cam_simulation | [ThermalCameraSimulation](#thermalcamerasimulation) |  | Specific parameters for a thermal camera. |
| output_splitting | [OutputSplitting](#outputsplitting) |  | Defines how the sensor output must be split.<br><br>\note Optional field. If not set, the output data is not split. |
| serialize_data | [google.protobuf.BoolValue](#boolvalue) |  | Indicates whether or not the data must be serialized during the <br>simulation.<br><br>When this parameter is set to true (which is the default value),<br>the data is serialized.<br><br>When this parameter is set to false, the data is unserialized.<br><br>Default value: true<br><br>\note Only Camera Output (Image) and Imager Output (Injection) data of <br>physics-based camera sensors can be unserialized.<br>Camera %Lens Output (Light), thermal camera, lidar and radar output data <br>are always serialized. |
| deploy_node_id | [string](#string) |  | The identifier of the deploy node on which the sensor will be spawned,<br>as defined in the deploy configuration.<br><br>\note Optional field. If not set, the sensor process is executed<br>on the local host. |
| data_access_settings | [DataAccessSettings](#dataaccesssettings) |  | Specifies the configuration for accessing and handling <br>sensor data. |

### SimulationParameters

\brief Contains general simulation parameters, as well as simulation 
parameters per sensor id. These parameters
define the accuracy of the simulation, the types of sensor outputs to
be generated and how they will be generated/stored.

\note %Simulation parameters may have an impact on the performance.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| sensor_simulation_parameters | [SensorParameters](#sensorparameters) | repeated | List of simulation parameters per sensor id. |
| lighting_system_parameters | [LightingSystemParameters](#lightingsystemparameters) |  | Lighting system parameters.<br><br>\note The lighting system parameters apply to all the lighting systems<br>defined for the ego vehicle. |
| pixel_segmentation_mapping | [vss.PixelSegmentationMapping](#pixelsegmentationmapping) |  | %Configuration of the tag-color mapping to be used <br>for the pixel segmentation camera output. |

### ThermalCameraSimulation

\brief Describes the simulation parameters for a thermal camera.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| rendering_parameters | [RenderingParameters](#renderingparameters) |  | The rendering engine parameters. |
| generate_temperature_map | [bool](#bool) |  | Activation of the temperature map output data by the thermal camera.<br><br>Default value: false |
| gpu_name | [string](#string) |  | The GPU name that must be used for the simulation of this <br>thermal camera sensor.<br><br>\note The GPU name must correspond to a GpuIdentifier name specified in<br>the deploy parameters.<br><br>\note Optional field. If not set, the default GPU (whose index is 0)<br>will be used. |

### TopLeftCornerPosition

\brief Describes the top left corner position of the rendering
window relative to the top left corner of the monitor.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| x | [int32](#int32) |  | The horizontal offset (in pixels) of the rendering window from the<br>top left corner of the monitor.<br><br>Default value: 1 |
| y | [int32](#int32) |  | The vertical offset (in pixels) of the rendering window from the<br>top left corner of the monitor.<br> <br>Default value: 1 |


### ColorMode

\brief The available color modes for the radar's debug view output.

| Name | Number | Description |
| ---- | ------ | ----------- |
| BLACKWHITE | 0 | %Color in shades of gray by the angle of incidence between the <br>surface and viewing direction. (Default value.) |
| COATING | 1 | %Color by the dielectric properties of the materials.<br><br>\note %Color assignment is determined by the material indices of each radar<br> simulation instance and is not deterministic.<br><br>Optionally shaded (when enable_material_shading is set to true <br>in RadarDebugViewParameters). |
| VELOCITY | 2 | %Color by the relative velocities. <br><br>The R, G and B values correspond respectively to the velocities in the<br>X, Y and Z direction. |
| NORMAL | 3 | %Color by the normal of the surfaces converted to RGB. |

### Qualities

\brief The possible values for quality factors.

| Name | Number | Description |
| ---- | ------ | ----------- |
| UNDEFINED | 0 | Undefined value. (The default value will apply.) |
| LOW | 1 | Low quality. |
| MEDIUM | 2 | Medium quality. |
| HIGH | 3 | High quality. |
| EXTREME | 4 | Extreme quality. (Default value.) |

### RadarOutputSplittingLevel

\brief The radar output splitting level.

| Name | Number | Description |
| ---- | ------ | ----------- |
| DEFAULT | 0 | Default value. Output data is not split. |
| MODE | 1 | Split by radar mode. |
| TRANSMITTER | 2 | Split by transmitter. |



## avx/vss/simulation/upload.proto





### ResourceUploader

\brief Upload Service

This service allows to upload data as byte stream using 
gRPC streaming capabilities.

| Method Name | Request Type | Response Type | Description |
| ----------- | ------------ | ------------- | ------------|
| UploadResource | [UploadRequest](#uploadrequest) stream | [.vss.Status](#status) | Requests resource uploading. |


## avx/vss/simulation/upload_data.proto



### UploadMetaData

\brief Provides information on the data to upload.

\note Should be sent in the first \c UploadRequest.
Metadata sent later will be ignored.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| resource_identifier | [string](#string) |  | **Deprecated.** The identifier of the resource to upload.<br><br>\warning This field is marked deprecated and might be removed in later <br>versions. Consider using the values field instead. |
| values | [UploadMetaData.ValuesEntry](#valuesentry) | repeated | Map containing various metadata values.<br>The key corresponds to the type of the metadata, such as <br>"ResourceIdentifier" for resource identifiers or "ResourceType"<br>for specifying the resource type.<br>The value holds the associated value for the respective<br>metadata type.<br><br>\note The field should contain at least one of the following<br>metadata entries: `ResourceType` or `ResourceIdentifier`. |

### UploadMetaData-ValuesEntry




| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| key | [string](#string) |  |  |
| value | [string](#string) |  |  |

### UploadRequest

\brief Upload request message.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| upload_metadata | [UploadMetaData](#uploadmetadata) |  | The metadata used to identify the data to upload. |
| data | [bytes](#bytes) |  | The data to upload. |




## avx/vss/simulation/world_update.proto



### EnvironmentUpdate

\brief Applies an update to the environment.

Indicates what is changing.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| date_time | [google.protobuf.Timestamp](#timestamp) |  | Time of day (as sent by the simulation framework) <br>applied to the AVX sky model. |
| streetLightsState | [State](#state) |  | State to be applied to the nodes tagged "Streetlight" <br>in the track.<br><br>\note Only the ON/OFF values are accepted. |

### KinematicProperties

\brief Properties that define the motion of a solid.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| position | [vss.Vector3D](#vector3d) |  | Position of the object in the world reference frame.<br><br>Unit: meters (m) |
| velocity | [vss.Vector3D](#vector3d) |  | Velocity of the object relative to the world reference frame.<br><br>Unit: meters per second (m/s) |
| orientation | [vss.EulerAngles](#eulerangles) |  | Orientation of the object relative to the world reference frame.<br><br>\note When applying the Euler angles update, it is done<br>in the standard order yaw, pitch, roll.<br><br>Unit: radians (rad) |
| angular_velocity | [vss.Vector3D](#vector3d) |  | The new angular velocity vector of the object expressed in the world<br>reference frame. <br><br>\note The value on the Y axis corresponds to the yaw rotation. The value<br>on the X axis corresponds to the pitch rotation. The value on the Z axis<br>corresponds to the roll rotation.<br><br>Unit: radians per second (rad/s) |

### ObjectKey

\brief Object key used to identify the nodes on which the update
 shall be applied.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| vss_identity | [vss.ObjectIdentifier](#objectidentifier) |  | The unique identifier of an object in the simulation.<br><br>\note The identifier is case-sensitive. It is the one defined in the <br>loaded configuration. Each asset has a unique vss_identity. |
| tag | [Tag](#tag) |  | Tags are attached to asset nodes during the asset preparation with <br>AVxcelerate Asset Preparation. The update will be applied on all the nodes<br>of the object whose tag matches the tag given here. |

### ObjectUpdate

\brief Update to be applied on an object.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| key | [ObjectKey](#objectkey) |  | Key defining the object nodes on which the update shall be applied. |
| kinematic_properties | [KinematicProperties](#kinematicproperties) |  | Kinematic properties update to be applied to the nodes matching the<br>ObjectKey.<br><br>\note All properties are absolute (i.e.the updates are applied with respect<br>to the root node of the track). |
| state | [State](#state) |  | State to be applied to the nodes matching the ObjectKey. Available states<br>are defined and attached to a node during the data preparation of the <br>asset with AVxcelerate Data Preparation. |

### State

\brief State defined on an object node.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| identifier | [string](#string) |  | \brief Unique identifier of the state as defined by the user in AVX<br>Data Preparation when building the object. |

### Tag

\brief Definition of the tag using or not an index.

\note For a complete description of the naming conventions and standards
that you should follow when tagging assets in AVxcelerate, refer to
the Data Preparation section of the AVxcelerate Sensors Simulator
User's Guide.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| name | [string](#string) |  | The name of the tag.<br><br> \note The possible tags are: Animal, Pedestrian, Vehicle, RoadSign,<br>StreetLight and SimulationObject (which corresponds to 'Object' <br>in AVxcelerate Asset Preparation). |
| index | [google.protobuf.Int32Value](#int32value) |  | The index.<br><br>\note The index is needed for some specific tags such as vehicle<br>wheels or indicator lights. |

### WorldUpdate

\brief Contains an update of the world to be applied to AVX.


| Field | Type | Label | Description |
| ----- | ---- | ----- | ----------- |
| simulation_time | [google.protobuf.Duration](#duration) |  | %Simulation time corresponding to this world update. The value is <br>represented as a count of seconds and fractions of seconds at <br>nanosecond resolution. |
| environment_updates | [EnvironmentUpdate](#environmentupdate) | repeated | Environment changes. |
| object_updates | [ObjectUpdate](#objectupdate) | repeated | List of all simulation object changes. |



## Scalar Value Types

| .proto Type | Notes | C++ | Java | Python | Go | C# | PHP | Ruby |
| ----------- | ----- | --- | ---- | ------ | -- | -- | --- | ---- |
| <div><h4 id="double" /></div><a name="double" /> double |  |  | double | double | float | float64 | double | float | Float |
| <div><h4 id="float" /></div><a name="float" /> float |  |  | float | float | float | float32 | float | float | Float |
| <div><h4 id="int32" /></div><a name="int32" /> int32 |  | Uses variable-length encoding. Inefficient for encoding negative numbers  if your field is likely to have negative values, use sint32 instead. | int32 | int | int | int32 | int | integer | Bignum or Fixnum (as required) |
| <div><h4 id="int64" /></div><a name="int64" /> int64 |  | Uses variable-length encoding. Inefficient for encoding negative numbers  if your field is likely to have negative values, use sint64 instead. | int64 | long | int/long | int64 | long | integer/string | Bignum |
| <div><h4 id="uint32" /></div><a name="uint32" /> uint32 |  | Uses variable-length encoding. | uint32 | int | int/long | uint32 | uint | integer | Bignum or Fixnum (as required) |
| <div><h4 id="uint64" /></div><a name="uint64" /> uint64 |  | Uses variable-length encoding. | uint64 | long | int/long | uint64 | ulong | integer/string | Bignum or Fixnum (as required) |
| <div><h4 id="sint32" /></div><a name="sint32" /> sint32 |  | Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int32s. | int32 | int | int | int32 | int | integer | Bignum or Fixnum (as required) |
| <div><h4 id="sint64" /></div><a name="sint64" /> sint64 |  | Uses variable-length encoding. Signed int value. These more efficiently encode negative numbers than regular int64s. | int64 | long | int/long | int64 | long | integer/string | Bignum |
| <div><h4 id="fixed32" /></div><a name="fixed32" /> fixed32 |  | Always four bytes. More efficient than uint32 if values are often greater than 2^28. | uint32 | int | int | uint32 | uint | integer | Bignum or Fixnum (as required) |
| <div><h4 id="fixed64" /></div><a name="fixed64" /> fixed64 |  | Always eight bytes. More efficient than uint64 if values are often greater than 2^56. | uint64 | long | int/long | uint64 | ulong | integer/string | Bignum |
| <div><h4 id="sfixed32" /></div><a name="sfixed32" /> sfixed32 |  | Always four bytes. | int32 | int | int | int32 | int | integer | Bignum or Fixnum (as required) |
| <div><h4 id="sfixed64" /></div><a name="sfixed64" /> sfixed64 |  | Always eight bytes. | int64 | long | int/long | int64 | long | integer/string | Bignum |
| <div><h4 id="bool" /></div><a name="bool" /> bool |  |  | bool | boolean | boolean | bool | bool | boolean | TrueClass/FalseClass |
| <div><h4 id="string" /></div><a name="string" /> string |  | A string must always contain UTF-8 encoded or 7-bit ASCII text. | string | String | str/unicode | string | string | string | String (UTF-8) |
| <div><h4 id="bytes" /></div><a name="bytes" /> bytes |  | May contain any arbitrary sequence of bytes. | string | ByteString | str | []byte | ByteString | string | String (ASCII-8BIT) |
