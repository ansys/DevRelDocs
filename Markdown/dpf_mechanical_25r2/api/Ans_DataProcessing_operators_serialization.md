---
uid: Ans.DataProcessing.operators.serialization
---

# Ans.DataProcessing.operators.serialization Namespace

## Classes

| Class | Description |
|-------|-------------|
| [csv_to_field](Ans_DataProcessing_operators_serialization_csv_to_field.md) | transform csv file to a field or fields container   ///available inputs: time_scoping (Scoping) (optional), data_sources (DataSources) |
| [data_tree_to_json](Ans_DataProcessing_operators_serialization_data_tree_to_json.md) | Writes a json file or string from a DataTree   ///available inputs: data_tree (DataTree), path (string) (optional) |
| [data_tree_to_txt](Ans_DataProcessing_operators_serialization_data_tree_to_txt.md) | Writes a txt file or string from a DataTree   ///available inputs: data_tree (DataTree), path (string) (optional) |
| [deserializer](Ans_DataProcessing_operators_serialization_deserializer.md) | Takes a file generated by the serializer and deserializes it into DPF's entities.   ///available inputs: stream_type (Int32), file_path (string) |
| [export_symbolic_workflow](Ans_DataProcessing_operators_serialization_export_symbolic_workflow.md) | Transforms a Workflow into a symbolic Workflow and writes it to a file (if a path is set in input) or string   ///available inputs: workflow (Workflow), path (string) (optional), format (Int32) (optional), options (Int32) (optional) |
| [field_to_csv](Ans_DataProcessing_operators_serialization_field_to_csv.md) | Exports a field or a fields container into a csv file   ///available inputs: field_or_fields_container (FieldsContainer, Field), file_path (string), storage_type (Int32) (optional) |
| [hdf5dpf_custom_read](Ans_DataProcessing_operators_serialization_hdf5dpf_custom_read.md) | Extract a custom result from an hdf5dpf file. This operator is deprecated, please use the 'custom' operator instead.   ///available inputs: time_scoping (Scoping) (optional), mesh_scoping (Scoping) (optional), streams (StreamsContainer) (optional), data_sources (DataSources) (optional), meta_data (DataTree) (optional), result_name (object) |
| [hdf5dpf_generate_result_file](Ans_DataProcessing_operators_serialization_hdf5dpf_generate_result_file.md) | Generate a dpf result file from provided information.   ///available inputs: append_mode (bool) (optional), dataset_size_compression_threshold (Int32) (optional), h5_native_compression (Int32, DataTree) (optional), export_floats (bool) (optional), filename (string), mesh_provider_out (MeshedRegion) (optional), time_freq_support_out (TimeFreqSupport) (optional), ansys_unit_system_id (Int32, ResultInfo) (optional), input_name1 (string, object) (optional), input_name2 (string, object) (optional) |
| [import_symbolic_workflow](Ans_DataProcessing_operators_serialization_import_symbolic_workflow.md) | Reads a file or string holding a Symbolic Workflow and instantiate a WorkFlow with its data.   ///available inputs: string_or_path (string, DataSources), format (Int32) (optional) |
| [json_to_data_tree](Ans_DataProcessing_operators_serialization_json_to_data_tree.md) | Reads a json file or string to a DataTree   ///available inputs: string_or_path (string, DataSources) |
| [mechanical_csv_to_field](Ans_DataProcessing_operators_serialization_mechanical_csv_to_field.md) | Reads mechanical exported csv file   ///available inputs: unit (), mesh (MeshedRegion) (optional), data_sources (DataSources), requested_location (string, FieldDefinition) |
| [migrate_file_to_vtk](Ans_DataProcessing_operators_serialization_migrate_file_to_vtk.md) | Take an input data sources or streams and convert as much data as possible to vtk.   ///available inputs: output_filename (string) (optional), streams_container (StreamsContainer) (optional), data_sources (DataSources) (optional) |
| [serialize_to_hdf5](Ans_DataProcessing_operators_serialization_serialize_to_hdf5.md) | This operator is deprecated: use 'hdf5::h5dpf::make_result_file' instead. Serialize the inputs in an hdf5 format.   ///available inputs: file_path (string), export_floats (bool) (optional), export_flat_vectors (bool) (optional), data1 (object), data2 (object) |
| [serializer](Ans_DataProcessing_operators_serialization_serializer.md) | Take any input and serialize them in a file.   ///available inputs: stream_type (Int32), file_path (string), any_input1 (object), any_input2 (object) |
| [serializer_to_string](Ans_DataProcessing_operators_serialization_serializer_to_string.md) | Take any input and serialize them in a string.   ///available inputs: stream_type (Int32), any_input1 (object), any_input2 (object) |
| [string_deserializer](Ans_DataProcessing_operators_serialization_string_deserializer.md) | Takes a string generated by the serializer and deserializes it into DPF's entities.   ///available inputs: stream_type (Int32), serialized_string1 (string), serialized_string2 (string) |
| [txt_to_data_tree](Ans_DataProcessing_operators_serialization_txt_to_data_tree.md) | Reads a txt file or string to a DataTree   ///available inputs: string_or_path (string, DataSources) |
| [vtk_export](Ans_DataProcessing_operators_serialization_vtk_export.md) | Write the input field and fields container into a given vtk path   ///available inputs: export_type (Int32) (optional), file_path (string), mesh (MeshedRegion) (optional), fields1 (FieldsContainer, Field), fields2 (FieldsContainer, Field) |
| [vtk_to_fields](Ans_DataProcessing_operators_serialization_vtk_to_fields.md) | Write a field based on a vtk file.   ///available inputs: field_name (string) (optional), streams (StreamsContainer) (optional), data_sources (DataSources) |
| [workflow_to_pydpf](Ans_DataProcessing_operators_serialization_workflow_to_pydpf.md) | Generates a PyDPF script that can recreate the given workflow. |
| [workflow_to_workflow_topology](Ans_DataProcessing_operators_serialization_workflow_to_workflow_topology.md) | Creates a GenericDataContainer based on WorkflowTopology structure from a Workflow object, allowing to access its operators, operator connections, data connections, and exposed pins.   ///available inputs: workflow (Workflow) |
